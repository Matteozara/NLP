{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_project.ipynb","provenance":[],"collapsed_sections":["zQWS8oTycuaj","9GY6fPeuid04","SBEmYL3BBO1u","bHA1FTW1Iozb"],"authorship_tag":"ABX9TyNkJKe8b8vJcasoTjeV1z2B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"t3u0RnILfmVi"},"outputs":[],"source":["import re\n","from collections import Counter\n","from typing import *\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torch import nn\n","import random\n","import numpy as np\n","from sklearn.metrics import f1_score"]},{"cell_type":"code","source":["SEED = 42\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"metadata":{"id":"S8TsZNSgvwLv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#path_train = '/content/drive/My Drive/results/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJsHCdPHi-nJ","executionInfo":{"status":"ok","timestamp":1649430638894,"user_tz":-120,"elapsed":20804,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"eeba7171-93a4-41d8-e683-2aed752368fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Load dataset and explore it"],"metadata":{"id":"rLBVNMQTWy43"}},{"cell_type":"code","source":["###\n","train_data['#'].describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zS_D9At4-Vp5","executionInfo":{"status":"ok","timestamp":1648462322722,"user_tz":-120,"elapsed":4,"user":{"displayName":"matteo zaramella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10742928843186045982"}},"outputId":"2ea12b64-d75d-416c-e532-d49ea586f291"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count     254592\n","unique     29965\n","top            #\n","freq       14534\n","Name: #, dtype: object"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["#function of the code below (use on training)\n","def load_dataset(path):\n","  data = pd.read_table(path, error_bad_lines=False, warn_bad_lines=False)\n","  # Remove the rows of the file that contain a \"NaN\" value.\n","  data.dropna() #if i remove this parameter it takes all the word (doesn't divide by phrases)\n","  return data"],"metadata":{"id":"7MMJPmE5u1Ar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_labels_distribution(data):\n","  l = data['id'].value_counts()\n","  l = l.drop([\"id\", 'O'])\n","  print(l)\n","  #plt.xlim(40, 160)\n","  #plt.ylim(0, 0.03)\n","  plt.figure(figsize=(15,8))\n","  plt.plot(l, color = \"skyblue\")\n","  plt.xlabel('Labels')\n","  plt.ylabel('Frequency')\n","  plt.title('Distribution of the labels')\n","\n","  plt.grid(True)\n","\n","def plot_50_top_words(data):\n","  l = data['#'].value_counts()\n","  l = l.head(50)\n","  #l = l.drop([\"id\", 'O'])\n","  #print(l)\n","\n","  #plt.xlim(40, 160)\n","  #plt.ylim(0, 0.03)\n","  plt.figure(figsize=(30,10))\n","  plt.plot(l, color = \"skyblue\", label='Sine wave')\n","  plt.xlabel('Words')\n","  plt.ylabel('Frequency')\n","  plt.title('50 most frequent words')\n","\n","  plt.grid(True)"],"metadata":{"id":"hvY0DBN0DHd9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###\n","#copied by notebook nlp\n","\n","import pandas as pd\n","\n","# Load the data into a pandas \"DataFrame\" object.\n","train_data = pd.read_table('/content/drive/MyDrive/data (1)/train.tsv', error_bad_lines=False, warn_bad_lines=False)\n","\n","# Remove the rows of the file that contain a \"NaN\" value.\n","train_data.dropna() #if i remove this parameter it takes all the word (doesn't divide by phrases)\n","\n","# Let's see what the file contains (returns the first 5 rows by default).\n","train_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"NEiIOWAOiXLR","executionInfo":{"status":"ok","timestamp":1649194101830,"user_tz":-120,"elapsed":299,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"12dc608f-6fc9-4c25-bb59-ab45737ad235"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n","/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]},{"output_type":"execute_result","data":{"text/plain":["               # id   0\n","0             it  O NaN\n","1           lies  O NaN\n","2  approximately  O NaN\n","3          north  O NaN\n","4           east  O NaN"],"text/html":["\n","  <div id=\"df-2544a51b-7e4c-49a7-84c1-c0abde35ca12\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>#</th>\n","      <th>id</th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>it</td>\n","      <td>O</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>lies</td>\n","      <td>O</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>approximately</td>\n","      <td>O</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>north</td>\n","      <td>O</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>east</td>\n","      <td>O</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2544a51b-7e4c-49a7-84c1-c0abde35ca12')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2544a51b-7e4c-49a7-84c1-c0abde35ca12 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2544a51b-7e4c-49a7-84c1-c0abde35ca12');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["l = train_data['id'].value_counts()\n","l = l.drop([\"id\", 'O'])\n","print(l)\n","\n","#plt.xlim(40, 160)\n","#plt.ylim(0, 0.03)\n","plt.figure(figsize=(15,8))\n","plt.plot(l, color = \"skyblue\")\n","plt.xlabel('Labels')\n","plt.ylabel('Frequency')\n","plt.title('Distribution of the labels')\n","\n","plt.grid(True)\n","#plt.hist(l, color = \"skyblue\", ec=\"skyblue\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":739},"id":"5vMvDYKa9UZI","executionInfo":{"status":"ok","timestamp":1648714277441,"user_tz":-120,"elapsed":817,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"43a9c4a8-4a50-4c86-ee9b-eaa662d3a267"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I-GRP     6084\n","I-PER     5805\n","I-CW      5716\n","B-PER     5090\n","B-LOC     4556\n","B-CW      3551\n","B-GRP     3375\n","I-CORP    2987\n","B-CORP    2975\n","B-PROD    2770\n","I-LOC     2598\n","I-PROD    1710\n","Name: id, dtype: int64\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x576 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#print the 50 most frequent words\n","l = train_data['#'].value_counts()\n","l = l.head(50)\n","#l = l.drop([\"id\", 'O'])\n","#print(l)\n","\n","#plt.xlim(40, 160)\n","#plt.ylim(0, 0.03)\n","plt.figure(figsize=(30,10))\n","plt.plot(l, color = \"skyblue\", label='Sine wave')\n","plt.xlabel('Words')\n","plt.ylabel('Frequency')\n","plt.title('50 most frequent words')\n","\n","plt.grid(True)\n","#plt.hist(l, color = \"skyblue\", ec=\"skyblue\")"],"metadata":{"id":"3vUUOUHVE3rE","colab":{"base_uri":"https://localhost:8080/","height":618},"executionInfo":{"status":"ok","timestamp":1648714283663,"user_tz":-120,"elapsed":1603,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"0f9ca14a-9ba8-44c2-be89-2c06796f3c51"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 2160x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["# Create dictionary"],"metadata":{"id":"MdusrWYNWgr-"}},{"cell_type":"code","source":["#try with wiki-50 (is faster)\n","\n","#load glove embeddings\n","import gensim.downloader as gen\n","\n","wv = gen.load('glove-wiki-gigaword-50')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRScMfC3jJsF","executionInfo":{"status":"ok","timestamp":1649444395810,"user_tz":-120,"elapsed":41187,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"539aeb92-15a1-4036-b1a4-c46fa41c0637"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 66.0/66.0MB downloaded\n"]}]},{"cell_type":"code","source":["#try with wiki-300\n","\n","#load glove embeddings\n","import gensim.downloader as gen\n","\n","wv = gen.load('glove-wiki-gigaword-300')"],"metadata":{"id":"gkcrPf6GqOZN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1649931488094,"user_tz":-120,"elapsed":150355,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"530ff90f-ec6a-4463-d20a-7746dc6f1dcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 376.1/376.1MB downloaded\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-15051c2c3eae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'glove-wiki-gigaword-300'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/root/gensim-data/glove-wiki-gigaword-300/__init__.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove-wiki-gigaword-300'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove-wiki-gigaword-300.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid vector on line %s (is this really the text format?)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mline_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0madd_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid vector on line %s (is this really the text format?)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mline_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0madd_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["#create a dictionary with all the words present on glove\n","words = wv.vocab"],"metadata":{"id":"09p5AMXMQ8-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create a dictionary from glove: word to index and index to word\n","\n","def default():\n","  dictionary_indices = {}\n","  dictionary_words = []\n","  dictionary_indices['pad'] = 0\n","  dictionary_words.append('pad')\n","  dictionary_indices['unk'] = 1\n","  dictionary_words.append('unk')\n","\n","  return dictionary_indices, dictionary_words\n","\n","\n","def create_dictionary(wv):\n","  dictionary_indice, dictionary_words = default()\n","  for i in wv:\n","    #print(i)\n","    if i != 'unk' and i != 'pad':\n","      dictionary_indice[i] = len(dictionary_indice)\n","      dictionary_words.append(i)\n","\n","  return dictionary_indice, dictionary_words\n"],"metadata":{"id":"dEjXkMI4PsOb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_to_indices, indices_to_word = create_dictionary(words)"],"metadata":{"id":"FVdGGNIbR9mt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###\n","word_to_indices['good']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zcqFm9LTCr6","executionInfo":{"status":"ok","timestamp":1648804484041,"user_tz":-120,"elapsed":414,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"1927180e-3741-4116-a4fc-60f1cdec9076"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["221"]},"metadata":{},"execution_count":107}]},{"cell_type":"code","source":["###\n","indices_to_word"],"metadata":{"id":"kU6hnSvbUX9E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create index to label and label to index\n","\n","label_to_indices = {'PAD' : 0, 'O' : 1, 'B-PER' : 2,'I-PER' : 3,'B-LOC' : 4,'I-LOC' : 5,'B-GRP' : 6,'I-GRP' : 7,'B-CORP' : 8,'I-CORP' : 9,'B-PROD' : 10,'I-PROD' : 11,'B-CW' : 12,'I-CW' : 13}\n","indices_to_label = ['PAD', 'O', 'B-PER' ,'I-PER' ,'B-LOC' ,'I-LOC' ,'B-GRP' ,'I-GRP' ,'B-CORP' ,'I-CORP' ,'B-PROD' ,'I-PROD' ,'B-CW' ,'I-CW']"],"metadata":{"id":"ttk8thvDV7yv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Encode dataset"],"metadata":{"id":"lwQW2uM2WoF5"}},{"cell_type":"code","source":["#convert dataset into a dictionary and count max words per phrase\n","def create_list(train_data):\n","  c = 0\n","  n_word = 0\n","  max = 0\n","  lista_train= {}\n","  lista = []\n","  for i in range(0, len(train_data)):\n","    if(train_data['#'][i] == '#'):\n","      lista_train[c] = lista\n","      if max < n_word:\n","        max = n_word\n","      lista = []\n","      n_word = 0\n","      c += 1\n","    else:\n","      lista.append([train_data['#'][i], train_data['id'][i]])\n","      n_word += 1\n","\n","  return lista_train, max"],"metadata":{"id":"ibZzCupHVDPe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###\n","lista_train, max = create_list(train_data)"],"metadata":{"id":"XhiCu-Xbr1Qb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(lista_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KsFm3mJkoQsY","executionInfo":{"status":"ok","timestamp":1649194230749,"user_tz":-120,"elapsed":306,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"5daf72e0-8d95-4d9c-ff4f-a036490b4188"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["#transform data so each phrase has the same length\n","def all_same_length(train, max):\n","  for i in train:\n","    diff = max - len(train[i]) \n","    if diff > 0:\n","      for x in range(0, diff):\n","        train[i].append(['pad', 'PAD'])\n","\n","  return train"],"metadata":{"id":"cZJuhFiyVYNa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#questo metodo fa tutte le singole scritte (lo chiamo nel training)\n","def dataset_creator(data, word_to_indices, label_to_indices):\n","  lista, max = create_list(data)\n","  same_length = all_same_length(lista, max)\n","  word_indices = dataset_to_indices(same_length, word_to_indices)\n","  label_ind, count_classes = label_index(same_length, label_to_indices)\n","\n","  data = {}\n","  for i in range(0, len(word_indices)):\n","    data[i]={'inputs': torch.LongTensor(word_indices[i]), 'outputs': torch.LongTensor(label_ind[i])}\n","\n","  return data, count_classes"],"metadata":{"id":"FgXVYx-TVJkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###\n","train_same_length = all_same_length(lista_train, max)"],"metadata":{"id":"brXHvT6CVe8j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###\n","print(train_same_length[0])\n","print(max)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PVKZoTLrVLZn","executionInfo":{"status":"ok","timestamp":1648804729507,"user_tz":-120,"elapsed":321,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"530f80b7-c04e-4ec4-a4fe-768fd2d4ef1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['it', 'O'], ['lies', 'O'], ['approximately', 'O'], ['north', 'O'], ['east', 'O'], ['of', 'O'], ['bolesławiec', 'B-LOC'], [',', 'O'], ['and', 'O'], ['west', 'O'], ['of', 'O'], ['the', 'O'], ['regional', 'O'], ['capital', 'O'], ['wrocław', 'B-LOC'], ['.', 'O'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD'], ['pad', 'PAD']]\n","41\n"]}]},{"cell_type":"code","source":["#Word into indices using vocabolary just create\n","\n","def dataset_to_indices(lista_train, w):\n","  word_indices = {}\n","  c = 0\n","\n","  for i in lista_train:\n","    indices = []\n","    for j in lista_train[i]:\n","      #print(j[1])\n","      try:\n","        indices.append(w[j[0]])\n","      except:\n","        indices.append(1) #if the word isn't on dictionary\n","    word_indices[c] = indices\n","    c += 1\n","  return word_indices\n"],"metadata":{"id":"LXjExGRQGBV-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###\n","word_indices = dataset_to_indices(train_same_length, word_to_indices)"],"metadata":{"id":"yMiwl-RiZHSq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###\n","word_indices[1]"],"metadata":{"id":"ilrXyp5RZKLk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#label to index\n","def label_index(lista_train, l):\n","  word_label = {}\n","  a = {'PAD' : 0, 'O' : 0, 'B-PER' : 0,'I-PER' : 0,'B-LOC' : 0,'I-LOC' : 0,'B-GRP' : 0,'I-GRP' : 0,'B-CORP' : 0,'I-CORP' : 0,'B-PROD' : 0,'I-PROD' : 0,'B-CW' : 0,'I-CW' : 0}\n","  c = 0\n","\n","  for i in lista_train:\n","    label = []\n","    for j in lista_train[i]:\n","      #print(j[1])\n","      label.append(l[j[1]])\n","      a[j[1]] += 1\n","    word_label[c] = label\n","    c += 1\n","  return word_label, a\n"],"metadata":{"id":"icx3UIxzvh4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###\n","label_ind_training = label_index(train_same_length, label_to_indices)"],"metadata":{"id":"fpCqTj9Wr2pd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###\n","len(label_ind_training)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uQ3dlAgCyxTW","executionInfo":{"status":"ok","timestamp":1648805031680,"user_tz":-120,"elapsed":316,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"a30e7cc8-e9aa-4629-f96c-0dc7e8b632d8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14534"]},"metadata":{},"execution_count":136}]},{"cell_type":"code","source":["###\n","print(label_ind_training[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sjoXsYPiy38n","executionInfo":{"status":"ok","timestamp":1648805122037,"user_tz":-120,"elapsed":349,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"5a2121af-cb1b-457d-c31e-cd364f082214"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[11, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"markdown","source":["# Try example"],"metadata":{"id":"zQWS8oTycuaj"}},{"cell_type":"code","source":["###\n","#try to embed with pytorch (made by them, but adapted)\n","#transform all phrases on vector with the same length (10)\n","\n","embedding_layer = nn.Embedding(len(word_to_indices), 10)\n","print(embedding_layer)\n","x_embeddings = embedding_layer(torch.LongTensor(word_indices[0]))\n","print(x_embeddings.shape)\n","print(x_embeddings[0])\n","print(x_embeddings[0].detach().numpy())\n","print(x_embeddings[0].tolist())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VuteE-eUL-YI","executionInfo":{"status":"ok","timestamp":1648805770190,"user_tz":-120,"elapsed":621,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"3a623686-fd29-4b8c-f750-71836ce6a8c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Embedding(400000, 10)\n","torch.Size([41, 10])\n","tensor([-1.8976,  0.0375, -2.7222,  0.8282,  0.3488, -0.3006, -1.4327, -0.6987,\n","         0.3991, -0.9670], grad_fn=<SelectBackward0>)\n","[-1.8975549   0.03754022 -2.7222123   0.8281561   0.3488142  -0.30064598\n"," -1.4326546  -0.6986831   0.3991374  -0.96700877]\n","[-1.897554874420166, 0.037540219724178314, -2.722212314605713, 0.8281561136245728, 0.3488141894340515, -0.30064597725868225, -1.432654619216919, -0.6986830830574036, 0.399137407541275, -0.9670087695121765]\n"]}]},{"cell_type":"code","source":["###\n","lstm = nn.LSTM(10, 5) # sequence length and hidden dimensions\n","lstm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CFLN2t23NI56","executionInfo":{"status":"ok","timestamp":1648805790721,"user_tz":-120,"elapsed":292,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"520b67a9-69d7-4daa-f8ff-016137cd1df0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LSTM(10, 5)"]},"metadata":{},"execution_count":143}]},{"cell_type":"code","source":["###\n","print(\"x_embeddings.shape =\", x_embeddings.shape)\n","batched_x_embeddings = x_embeddings.unsqueeze(1) # adding the batch dimension (with 1 element)\n","print(\"batched_x_embeddings.shape =\",batched_x_embeddings.shape)\n","o, (h, c) = lstm(batched_x_embeddings)\n","\n","print(\"o.shape =\", o.shape)\n","o = o.squeeze() # removing the batch dimension with one element only\n","print(\"o.shape =\", o.shape)\n","print(\"x_embeddings.shape =\", x_embeddings.shape)\n","print(o[3].detach().numpy()) # detach disconnects the tensor from the computation graph\n","print(x_embeddings[3].detach().numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPMEfKPaNUDx","executionInfo":{"status":"ok","timestamp":1648805801660,"user_tz":-120,"elapsed":240,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"a83c1fc7-2c95-4809-d228-03f2bd924925"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_embeddings.shape = torch.Size([41, 10])\n","batched_x_embeddings.shape = torch.Size([41, 1, 10])\n","o.shape = torch.Size([41, 1, 5])\n","o.shape = torch.Size([41, 5])\n","x_embeddings.shape = torch.Size([41, 10])\n","[0.05411072 0.02916004 0.13606599 0.06811907 0.35106528]\n","[ 0.80763346  0.80125624 -0.04134348  1.1182485   0.6730789  -0.6136849\n"," -1.4124391  -1.525016   -0.6530907   2.2377603 ]\n"]}]},{"cell_type":"code","source":["###\n","h"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tyyKvTYaPZo6","executionInfo":{"status":"ok","timestamp":1648805807542,"user_tz":-120,"elapsed":286,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"f5d7e228-43b5-4c87-c548-6fbc9f5182b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.7380,  0.3503, -0.1526, -0.3178, -0.4165]]],\n","       grad_fn=<StackBackward0>)"]},"metadata":{},"execution_count":145}]},{"cell_type":"code","source":["###\n","classifier = nn.Linear(5, len(indices_to_label)) \n","classifier"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kTLoSRXmN6vt","executionInfo":{"status":"ok","timestamp":1648805846035,"user_tz":-120,"elapsed":482,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"ebb8e955-f314-410a-d604-899c28a117e6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=5, out_features=14, bias=True)"]},"metadata":{},"execution_count":146}]},{"cell_type":"code","source":["###\n","output = classifier(o)\n","print(\"output.shape =\", output.shape)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gBSJv9ToOd6J","executionInfo":{"status":"ok","timestamp":1648805850882,"user_tz":-120,"elapsed":517,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"46ffb6d6-ad96-4ad6-df75-3c79a87858f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["output.shape = torch.Size([41, 14])\n","tensor([[-0.2779, -0.2319, -0.2223, -0.4507,  0.1513, -0.0276,  0.2003,  0.1500,\n","          0.0302, -0.3189, -0.5023,  0.1075,  0.2007, -0.1875],\n","        [-0.1346, -0.0342, -0.2317, -0.5664,  0.0684, -0.1403,  0.1279,  0.1970,\n","         -0.0111, -0.5292, -0.3387,  0.1735,  0.2443, -0.4725],\n","        [-0.2293, -0.1684, -0.4380, -0.4737, -0.1950, -0.1774, -0.0805,  0.2631,\n","          0.1466, -0.3953, -0.3724, -0.0567,  0.1317, -0.1968],\n","        [-0.4342, -0.2166, -0.4272, -0.4144, -0.0062, -0.0671, -0.0371,  0.1254,\n","         -0.0554, -0.4452, -0.3411, -0.1684,  0.0420, -0.3569],\n","        [-0.3472, -0.0501, -0.5384, -0.4108, -0.1653, -0.1339, -0.1518,  0.1720,\n","         -0.0216, -0.4690, -0.1524, -0.2668, -0.0758, -0.5161],\n","        [-0.2536,  0.0159, -0.5453, -0.4507, -0.2450, -0.1878, -0.1794,  0.2349,\n","          0.0615, -0.4664, -0.1312, -0.2495, -0.0506, -0.5153],\n","        [-0.2190, -0.1026, -0.3507, -0.4499, -0.0151, -0.1054,  0.0568,  0.1727,\n","         -0.0029, -0.4202, -0.3070,  0.0438,  0.1002, -0.3666],\n","        [-0.1361, -0.1171, -0.3990, -0.4713, -0.1929, -0.1745, -0.0187,  0.2976,\n","          0.2269, -0.3011, -0.3800, -0.0079,  0.1343, -0.1488],\n","        [-0.1124, -0.1607, -0.3962, -0.4576, -0.2232, -0.1762, -0.0079,  0.3239,\n","          0.2940, -0.2318, -0.4371,  0.0183,  0.1540, -0.0202],\n","        [-0.1273, -0.1008, -0.2958, -0.4332,  0.0108, -0.0920,  0.1449,  0.1821,\n","          0.0323, -0.3432, -0.3399,  0.1751,  0.1278, -0.2783],\n","        [-0.0914,  0.0326, -0.4766, -0.4350, -0.2331, -0.1909, -0.0684,  0.2472,\n","          0.0826, -0.4047, -0.1479, -0.0106, -0.0014, -0.4193],\n","        [-0.0902, -0.0706, -0.4226, -0.4054, -0.1834, -0.1527,  0.0120,  0.2425,\n","          0.1218, -0.3082, -0.2683,  0.0788,  0.0493, -0.2298],\n","        [-0.0619, -0.0200, -0.3909, -0.3963, -0.1188, -0.1318,  0.0667,  0.2030,\n","          0.0431, -0.3379, -0.2114,  0.1452,  0.0302, -0.3320],\n","        [-0.1424, -0.0375, -0.5410, -0.3721, -0.2641, -0.1799, -0.1097,  0.1938,\n","         -0.0177, -0.4449, -0.1125,  0.0190, -0.0521, -0.4007],\n","        [-0.0409,  0.0202, -0.5566, -0.4108, -0.3829, -0.2387, -0.1487,  0.2986,\n","          0.1642, -0.3619, -0.1325, -0.0209, -0.0286, -0.3105],\n","        [-0.1008, -0.0114, -0.4822, -0.3531, -0.1707, -0.1445, -0.0147,  0.1451,\n","         -0.1014, -0.4526, -0.0849,  0.1424, -0.0526, -0.4584],\n","        [-0.0850, -0.1279, -0.3260, -0.3725, -0.0241, -0.0871,  0.1551,  0.1553,\n","         -0.0165, -0.3269, -0.3046,  0.2808,  0.0910, -0.2256],\n","        [-0.1161, -0.2517, -0.2309, -0.3411,  0.1069, -0.0167,  0.2846,  0.1144,\n","         -0.0307, -0.2451, -0.4461,  0.3984,  0.1571, -0.0603],\n","        [-0.1321, -0.3022, -0.1972, -0.3241,  0.1577,  0.0133,  0.3342,  0.0960,\n","         -0.0384, -0.2096, -0.4995,  0.4403,  0.1770,  0.0059],\n","        [-0.1375, -0.3222, -0.1862, -0.3157,  0.1746,  0.0247,  0.3523,  0.0892,\n","         -0.0404, -0.1939, -0.5193,  0.4563,  0.1827,  0.0340],\n","        [-0.1395, -0.3312, -0.1824, -0.3113,  0.1806,  0.0295,  0.3595,  0.0864,\n","         -0.0408, -0.1862, -0.5275,  0.4633,  0.1844,  0.0476],\n","        [-0.1404, -0.3360, -0.1811, -0.3086,  0.1829,  0.0318,  0.3627,  0.0850,\n","         -0.0410, -0.1821, -0.5314,  0.4668,  0.1847,  0.0549],\n","        [-0.1410, -0.3388, -0.1807, -0.3068,  0.1838,  0.0331,  0.3642,  0.0842,\n","         -0.0413, -0.1798, -0.5333,  0.4689,  0.1847,  0.0592],\n","        [-0.1413, -0.3406, -0.1807, -0.3055,  0.1841,  0.0338,  0.3650,  0.0836,\n","         -0.0416, -0.1784, -0.5343,  0.4701,  0.1844,  0.0619],\n","        [-0.1416, -0.3419, -0.1808, -0.3046,  0.1842,  0.0343,  0.3654,  0.0831,\n","         -0.0419, -0.1775, -0.5349,  0.4709,  0.1841,  0.0638],\n","        [-0.1419, -0.3428, -0.1811, -0.3038,  0.1841,  0.0347,  0.3656,  0.0828,\n","         -0.0422, -0.1769, -0.5352,  0.4715,  0.1837,  0.0651],\n","        [-0.1421, -0.3435, -0.1814, -0.3032,  0.1840,  0.0349,  0.3657,  0.0825,\n","         -0.0424, -0.1764, -0.5353,  0.4718,  0.1834,  0.0660],\n","        [-0.1422, -0.3441, -0.1816, -0.3027,  0.1839,  0.0351,  0.3657,  0.0822,\n","         -0.0427, -0.1761, -0.5354,  0.4721,  0.1831,  0.0667],\n","        [-0.1424, -0.3445, -0.1819, -0.3023,  0.1838,  0.0352,  0.3657,  0.0820,\n","         -0.0429, -0.1759, -0.5354,  0.4723,  0.1828,  0.0672],\n","        [-0.1425, -0.3448, -0.1821, -0.3019,  0.1836,  0.0354,  0.3656,  0.0819,\n","         -0.0431, -0.1757, -0.5354,  0.4724,  0.1826,  0.0676],\n","        [-0.1427, -0.3451, -0.1823, -0.3016,  0.1835,  0.0354,  0.3655,  0.0817,\n","         -0.0433, -0.1756, -0.5353,  0.4725,  0.1824,  0.0679],\n","        [-0.1428, -0.3453, -0.1825, -0.3014,  0.1834,  0.0355,  0.3655,  0.0816,\n","         -0.0435, -0.1755, -0.5353,  0.4726,  0.1822,  0.0681],\n","        [-0.1428, -0.3455, -0.1826, -0.3011,  0.1833,  0.0356,  0.3654,  0.0815,\n","         -0.0436, -0.1754, -0.5352,  0.4726,  0.1820,  0.0683],\n","        [-0.1429, -0.3456, -0.1828, -0.3010,  0.1832,  0.0356,  0.3654,  0.0814,\n","         -0.0437, -0.1754, -0.5352,  0.4727,  0.1818,  0.0685],\n","        [-0.1430, -0.3458, -0.1829, -0.3008,  0.1831,  0.0356,  0.3653,  0.0814,\n","         -0.0438, -0.1753, -0.5351,  0.4727,  0.1817,  0.0686],\n","        [-0.1430, -0.3459, -0.1830, -0.3007,  0.1831,  0.0357,  0.3653,  0.0813,\n","         -0.0439, -0.1753, -0.5351,  0.4727,  0.1816,  0.0687],\n","        [-0.1431, -0.3460, -0.1831, -0.3006,  0.1830,  0.0357,  0.3652,  0.0812,\n","         -0.0440, -0.1753, -0.5351,  0.4728,  0.1815,  0.0688],\n","        [-0.1431, -0.3460, -0.1832, -0.3005,  0.1830,  0.0357,  0.3652,  0.0812,\n","         -0.0441, -0.1752, -0.5350,  0.4728,  0.1814,  0.0689],\n","        [-0.1432, -0.3461, -0.1832, -0.3004,  0.1829,  0.0357,  0.3652,  0.0812,\n","         -0.0441, -0.1752, -0.5350,  0.4728,  0.1814,  0.0689],\n","        [-0.1432, -0.3461, -0.1833, -0.3004,  0.1829,  0.0358,  0.3651,  0.0811,\n","         -0.0442, -0.1752, -0.5350,  0.4728,  0.1813,  0.0690],\n","        [-0.1432, -0.3462, -0.1833, -0.3003,  0.1829,  0.0358,  0.3651,  0.0811,\n","         -0.0442, -0.1752, -0.5349,  0.4728,  0.1812,  0.0690]],\n","       grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":["###\n","#assign results\n","print(output)\n","top_label_scores, top_label_indices = torch.max(output, -1)\n","\n","top_label_indices = top_label_indices.tolist()\n","print('indices_assigned: ', top_label_indices, 'lunghezza: ', len(top_label_indices))\n","print('indices_correct: ', label_ind_training[0], 'lunghezza: ', len(label_ind_training[0]))\n","print('score: ', top_label_scores)\n","\n","k = 0\n","for i in top_label_indices:\n","  print('label_assigned: ', indices_to_label[i])\n","  print('label_correct: ', indices_to_label[label_ind_training[0][k]])\n","  k += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzblli1DOqpk","executionInfo":{"status":"ok","timestamp":1648806003562,"user_tz":-120,"elapsed":309,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"738b6951-6e4c-4218-9cfd-1f8f4789218f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.2779, -0.2319, -0.2223, -0.4507,  0.1513, -0.0276,  0.2003,  0.1500,\n","          0.0302, -0.3189, -0.5023,  0.1075,  0.2007, -0.1875],\n","        [-0.1346, -0.0342, -0.2317, -0.5664,  0.0684, -0.1403,  0.1279,  0.1970,\n","         -0.0111, -0.5292, -0.3387,  0.1735,  0.2443, -0.4725],\n","        [-0.2293, -0.1684, -0.4380, -0.4737, -0.1950, -0.1774, -0.0805,  0.2631,\n","          0.1466, -0.3953, -0.3724, -0.0567,  0.1317, -0.1968],\n","        [-0.4342, -0.2166, -0.4272, -0.4144, -0.0062, -0.0671, -0.0371,  0.1254,\n","         -0.0554, -0.4452, -0.3411, -0.1684,  0.0420, -0.3569],\n","        [-0.3472, -0.0501, -0.5384, -0.4108, -0.1653, -0.1339, -0.1518,  0.1720,\n","         -0.0216, -0.4690, -0.1524, -0.2668, -0.0758, -0.5161],\n","        [-0.2536,  0.0159, -0.5453, -0.4507, -0.2450, -0.1878, -0.1794,  0.2349,\n","          0.0615, -0.4664, -0.1312, -0.2495, -0.0506, -0.5153],\n","        [-0.2190, -0.1026, -0.3507, -0.4499, -0.0151, -0.1054,  0.0568,  0.1727,\n","         -0.0029, -0.4202, -0.3070,  0.0438,  0.1002, -0.3666],\n","        [-0.1361, -0.1171, -0.3990, -0.4713, -0.1929, -0.1745, -0.0187,  0.2976,\n","          0.2269, -0.3011, -0.3800, -0.0079,  0.1343, -0.1488],\n","        [-0.1124, -0.1607, -0.3962, -0.4576, -0.2232, -0.1762, -0.0079,  0.3239,\n","          0.2940, -0.2318, -0.4371,  0.0183,  0.1540, -0.0202],\n","        [-0.1273, -0.1008, -0.2958, -0.4332,  0.0108, -0.0920,  0.1449,  0.1821,\n","          0.0323, -0.3432, -0.3399,  0.1751,  0.1278, -0.2783],\n","        [-0.0914,  0.0326, -0.4766, -0.4350, -0.2331, -0.1909, -0.0684,  0.2472,\n","          0.0826, -0.4047, -0.1479, -0.0106, -0.0014, -0.4193],\n","        [-0.0902, -0.0706, -0.4226, -0.4054, -0.1834, -0.1527,  0.0120,  0.2425,\n","          0.1218, -0.3082, -0.2683,  0.0788,  0.0493, -0.2298],\n","        [-0.0619, -0.0200, -0.3909, -0.3963, -0.1188, -0.1318,  0.0667,  0.2030,\n","          0.0431, -0.3379, -0.2114,  0.1452,  0.0302, -0.3320],\n","        [-0.1424, -0.0375, -0.5410, -0.3721, -0.2641, -0.1799, -0.1097,  0.1938,\n","         -0.0177, -0.4449, -0.1125,  0.0190, -0.0521, -0.4007],\n","        [-0.0409,  0.0202, -0.5566, -0.4108, -0.3829, -0.2387, -0.1487,  0.2986,\n","          0.1642, -0.3619, -0.1325, -0.0209, -0.0286, -0.3105],\n","        [-0.1008, -0.0114, -0.4822, -0.3531, -0.1707, -0.1445, -0.0147,  0.1451,\n","         -0.1014, -0.4526, -0.0849,  0.1424, -0.0526, -0.4584],\n","        [-0.0850, -0.1279, -0.3260, -0.3725, -0.0241, -0.0871,  0.1551,  0.1553,\n","         -0.0165, -0.3269, -0.3046,  0.2808,  0.0910, -0.2256],\n","        [-0.1161, -0.2517, -0.2309, -0.3411,  0.1069, -0.0167,  0.2846,  0.1144,\n","         -0.0307, -0.2451, -0.4461,  0.3984,  0.1571, -0.0603],\n","        [-0.1321, -0.3022, -0.1972, -0.3241,  0.1577,  0.0133,  0.3342,  0.0960,\n","         -0.0384, -0.2096, -0.4995,  0.4403,  0.1770,  0.0059],\n","        [-0.1375, -0.3222, -0.1862, -0.3157,  0.1746,  0.0247,  0.3523,  0.0892,\n","         -0.0404, -0.1939, -0.5193,  0.4563,  0.1827,  0.0340],\n","        [-0.1395, -0.3312, -0.1824, -0.3113,  0.1806,  0.0295,  0.3595,  0.0864,\n","         -0.0408, -0.1862, -0.5275,  0.4633,  0.1844,  0.0476],\n","        [-0.1404, -0.3360, -0.1811, -0.3086,  0.1829,  0.0318,  0.3627,  0.0850,\n","         -0.0410, -0.1821, -0.5314,  0.4668,  0.1847,  0.0549],\n","        [-0.1410, -0.3388, -0.1807, -0.3068,  0.1838,  0.0331,  0.3642,  0.0842,\n","         -0.0413, -0.1798, -0.5333,  0.4689,  0.1847,  0.0592],\n","        [-0.1413, -0.3406, -0.1807, -0.3055,  0.1841,  0.0338,  0.3650,  0.0836,\n","         -0.0416, -0.1784, -0.5343,  0.4701,  0.1844,  0.0619],\n","        [-0.1416, -0.3419, -0.1808, -0.3046,  0.1842,  0.0343,  0.3654,  0.0831,\n","         -0.0419, -0.1775, -0.5349,  0.4709,  0.1841,  0.0638],\n","        [-0.1419, -0.3428, -0.1811, -0.3038,  0.1841,  0.0347,  0.3656,  0.0828,\n","         -0.0422, -0.1769, -0.5352,  0.4715,  0.1837,  0.0651],\n","        [-0.1421, -0.3435, -0.1814, -0.3032,  0.1840,  0.0349,  0.3657,  0.0825,\n","         -0.0424, -0.1764, -0.5353,  0.4718,  0.1834,  0.0660],\n","        [-0.1422, -0.3441, -0.1816, -0.3027,  0.1839,  0.0351,  0.3657,  0.0822,\n","         -0.0427, -0.1761, -0.5354,  0.4721,  0.1831,  0.0667],\n","        [-0.1424, -0.3445, -0.1819, -0.3023,  0.1838,  0.0352,  0.3657,  0.0820,\n","         -0.0429, -0.1759, -0.5354,  0.4723,  0.1828,  0.0672],\n","        [-0.1425, -0.3448, -0.1821, -0.3019,  0.1836,  0.0354,  0.3656,  0.0819,\n","         -0.0431, -0.1757, -0.5354,  0.4724,  0.1826,  0.0676],\n","        [-0.1427, -0.3451, -0.1823, -0.3016,  0.1835,  0.0354,  0.3655,  0.0817,\n","         -0.0433, -0.1756, -0.5353,  0.4725,  0.1824,  0.0679],\n","        [-0.1428, -0.3453, -0.1825, -0.3014,  0.1834,  0.0355,  0.3655,  0.0816,\n","         -0.0435, -0.1755, -0.5353,  0.4726,  0.1822,  0.0681],\n","        [-0.1428, -0.3455, -0.1826, -0.3011,  0.1833,  0.0356,  0.3654,  0.0815,\n","         -0.0436, -0.1754, -0.5352,  0.4726,  0.1820,  0.0683],\n","        [-0.1429, -0.3456, -0.1828, -0.3010,  0.1832,  0.0356,  0.3654,  0.0814,\n","         -0.0437, -0.1754, -0.5352,  0.4727,  0.1818,  0.0685],\n","        [-0.1430, -0.3458, -0.1829, -0.3008,  0.1831,  0.0356,  0.3653,  0.0814,\n","         -0.0438, -0.1753, -0.5351,  0.4727,  0.1817,  0.0686],\n","        [-0.1430, -0.3459, -0.1830, -0.3007,  0.1831,  0.0357,  0.3653,  0.0813,\n","         -0.0439, -0.1753, -0.5351,  0.4727,  0.1816,  0.0687],\n","        [-0.1431, -0.3460, -0.1831, -0.3006,  0.1830,  0.0357,  0.3652,  0.0812,\n","         -0.0440, -0.1753, -0.5351,  0.4728,  0.1815,  0.0688],\n","        [-0.1431, -0.3460, -0.1832, -0.3005,  0.1830,  0.0357,  0.3652,  0.0812,\n","         -0.0441, -0.1752, -0.5350,  0.4728,  0.1814,  0.0689],\n","        [-0.1432, -0.3461, -0.1832, -0.3004,  0.1829,  0.0357,  0.3652,  0.0812,\n","         -0.0441, -0.1752, -0.5350,  0.4728,  0.1814,  0.0689],\n","        [-0.1432, -0.3461, -0.1833, -0.3004,  0.1829,  0.0358,  0.3651,  0.0811,\n","         -0.0442, -0.1752, -0.5350,  0.4728,  0.1813,  0.0690],\n","        [-0.1432, -0.3462, -0.1833, -0.3003,  0.1829,  0.0358,  0.3651,  0.0811,\n","         -0.0442, -0.1752, -0.5349,  0.4728,  0.1812,  0.0690]],\n","       grad_fn=<AddmmBackward0>)\n","indices_assigned:  [12, 12, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11] lunghezza:  41\n","indices_correct:  [13, 13, 13, 13, 13, 13, 3, 13, 13, 13, 13, 13, 13, 13, 3, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] lunghezza:  41\n","score:  tensor([0.2007, 0.2443, 0.2631, 0.1254, 0.1720, 0.2349, 0.1727, 0.2976, 0.3239,\n","        0.1821, 0.2472, 0.2425, 0.2030, 0.1938, 0.2986, 0.1451, 0.2808, 0.3984,\n","        0.4403, 0.4563, 0.4633, 0.4668, 0.4689, 0.4701, 0.4709, 0.4715, 0.4718,\n","        0.4721, 0.4723, 0.4724, 0.4725, 0.4726, 0.4726, 0.4727, 0.4727, 0.4727,\n","        0.4728, 0.4728, 0.4728, 0.4728, 0.4728], grad_fn=<MaxBackward0>)\n","label_assigned:  I-CW\n","label_correct:  O\n","label_assigned:  I-CW\n","label_correct:  O\n","label_assigned:  B-CORP\n","label_correct:  O\n","label_assigned:  B-CORP\n","label_correct:  O\n","label_assigned:  B-CORP\n","label_correct:  O\n","label_assigned:  B-CORP\n","label_correct:  O\n","label_assigned:  B-CORP\n","label_correct:  B-LOC\n","label_assigned:  B-CORP\n","label_correct:  O\n","label_assigned:  B-CORP\n","label_correct:  O\n","label_assigned:  B-CORP\n","label_correct:  O\n","label_assigned:  B-CORP\n","label_correct:  O\n","label_assigned:  B-CORP\n","label_correct:  O\n","label_assigned:  B-CORP\n","label_correct:  O\n","label_assigned:  B-CORP\n","label_correct:  O\n","label_assigned:  B-CORP\n","label_correct:  B-LOC\n","label_assigned:  B-CORP\n","label_correct:  O\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n","label_assigned:  B-CW\n","label_correct:  PAD\n"]}]},{"cell_type":"markdown","source":["# Build model"],"metadata":{"id":"UyNkHTCXVIn7"}},{"cell_type":"code","source":["class ClassifierModel(nn.Module):\n","    # we provide the hyperparameters as input\n","    def __init__(self, hparams):\n","        super(ClassifierModel, self).__init__()\n","        # Embedding layer: a mat∂rix vocab_size x embedding_dim where each index \n","        # correspond to a word in the vocabulary and the i-th row corresponds to \n","        # a latent representation of the i-th word in the vocabulary.\n","        print(params)\n","        self.word_embedding = nn.Embedding(hparams.vocab_size, hparams.embedding_dim)\n","        if hparams.embeddings is not None:\n","            print(\"initializing embeddings from pretrained\")\n","            self.word_embedding.weight.data.copy_(hparams.embeddings)\n","\n","        # LSTM layer: an LSTM neural network that process the input text\n","        # (encoded with word embeddings) from left to right and outputs \n","        # a new **contextual** representation of each word that depend\n","        # on the preciding words.\n","        self.lstm = nn.LSTM(hparams.embedding_dim, hparams.hidden_dim, \n","                            bidirectional=hparams.bidirectional,\n","                            num_layers=hparams.num_layers, \n","                            dropout = hparams.dropout if hparams.num_layers > 1 else 0)\n","        # Hidden layer: transforms the input value/scalar into\n","        # a hidden vector representation.\n","        lstm_output_dim = hparams.hidden_dim if hparams.bidirectional is False else hparams.hidden_dim * 2\n","\n","        # During training, randomly zeroes some of the elements of the \n","        # input tensor with probability hparams.dropout using samples \n","        # from a Bernoulli distribution. Each channel will be zeroed out \n","        # independently on every forward call.\n","        # This has proven to be an effective technique for regularization and \n","        # preventing the co-adaptation of neurons\n","        self.dropout = nn.Dropout(hparams.dropout)\n","        self.classifier = nn.Linear(lstm_output_dim, hparams.num_classes)\n","\n","    \n","    def forward(self, x):\n","        embeddings = self.word_embedding(x)\n","        print('INPUT: ', embeddings.size())\n","        embeddings = self.dropout(embeddings)\n","        o, (h, c) = self.lstm(embeddings)\n","        o = self.dropout(o)\n","        output = self.classifier(o)\n","        return output\n","\n","        "],"metadata":{"id":"qXraAJs7VL96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class HParams():\n","    vocab_size = len(word_to_indices)\n","    hidden_dim = 128\n","    embedding_dim = 100\n","    num_classes = len(indices_to_label)\n","    bidirectional = True\n","    num_layers = 3\n","    dropout = 0.05\n","    embeddings = None\n","params = HParams()"],"metadata":{"id":"GSQA8ImzV5Pu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###\n","postagger = ClassifierModel(params)#.cuda()\n","postagger"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_g0SwqUlWGEQ","executionInfo":{"status":"ok","timestamp":1648849966643,"user_tz":-120,"elapsed":708,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"bd0ff5d8-4f5d-415a-a17e-65a1df7170c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.HParams object at 0x7f07b306da50>\n"]},{"output_type":"execute_result","data":{"text/plain":["ClassifierModel(\n","  (word_embedding): Embedding(400000, 100)\n","  (lstm): LSTM(100, 128)\n","  (dropout): Dropout(p=0.0, inplace=False)\n","  (classifier): Linear(in_features=128, out_features=14, bias=True)\n",")"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["###\n","len(word_to_indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Go3y0cXnE-Z","executionInfo":{"status":"ok","timestamp":1648807979152,"user_tz":-120,"elapsed":236,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"095e87a5-7a76-416b-ce6a-2f66df41c50e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["400000"]},"metadata":{},"execution_count":197}]},{"cell_type":"code","source":["###\n","# the first 10 sentences\n","lista_10 = []\n","count = 0\n","for i in word_indices:\n","  count += 1\n","  #print(word_indices[i])\n","  lista_10.append(torch.LongTensor(word_indices[i]))\n","  if count > 9:\n","    break\n","\n","\n","encoded_input = lista_10\n","logits = postagger(torch.stack(encoded_input, 0))#.cuda())\n","\n","top_label_scores, top_label_indices = torch.max(logits, -1)\n","top_label_indices = top_label_indices.tolist()"],"metadata":{"id":"e8udKkMXWRzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###\n","for i in range(0, len(top_label_indices)):\n","    print('predicted labels: ', top_label_indices[i])\n","    print('correct labels: ', label_ind_training[i])\n","    print('--------------------------------------------------------------------------')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UM1ANw_8mS27","executionInfo":{"status":"ok","timestamp":1648808208763,"user_tz":-120,"elapsed":321,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"9412cc32-0707-4d79-b2c2-44571d122716"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["predicted labels:  [3, 9, 11, 6, 7, 6, 6, 11, 7, 1, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","correct labels:  [13, 13, 13, 13, 13, 13, 3, 13, 13, 13, 13, 13, 13, 13, 3, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","--------------------------------------------------------------------------\n","predicted labels:  [3, 7, 6, 7, 3, 3, 3, 1, 7, 3, 3, 7, 11, 6, 6, 2, 3, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","correct labels:  [11, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","--------------------------------------------------------------------------\n","predicted labels:  [7, 10, 6, 7, 7, 11, 6, 6, 11, 1, 7, 11, 5, 6, 6, 7, 7, 7, 3, 6, 6, 6, 11, 11, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","correct labels:  [1, 2, 13, 1, 2, 13, 1, 2, 13, 1, 2, 13, 1, 2, 13, 1, 2, 13, 1, 2, 13, 13, 13, 13, 13, 13, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","--------------------------------------------------------------------------\n","predicted labels:  [0, 10, 6, 11, 7, 3, 6, 7, 9, 6, 3, 6, 5, 6, 6, 3, 7, 6, 6, 6, 6, 5, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","correct labels:  [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 7, 8, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","--------------------------------------------------------------------------\n","predicted labels:  [5, 7, 6, 11, 8, 6, 6, 6, 5, 6, 7, 2, 5, 7, 6, 11, 1, 12, 6, 6, 11, 7, 11, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","correct labels:  [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 5, 6, 13, 13, 13, 13, 13, 13, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","--------------------------------------------------------------------------\n","predicted labels:  [7, 10, 6, 7, 7, 6, 3, 6, 6, 6, 11, 9, 5, 2, 10, 6, 6, 12, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","correct labels:  [13, 13, 13, 13, 13, 13, 13, 13, 13, 9, 13, 13, 13, 9, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","--------------------------------------------------------------------------\n","predicted labels:  [3, 7, 5, 9, 3, 7, 3, 5, 7, 5, 7, 6, 5, 2, 7, 3, 12, 6, 6, 12, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","correct labels:  [13, 13, 13, 13, 11, 13, 13, 13, 13, 13, 13, 11, 12, 13, 13, 11, 12, 13, 13, 13, 13, 13, 13, 13, 7, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","--------------------------------------------------------------------------\n","predicted labels:  [11, 6, 7, 3, 11, 11, 6, 5, 1, 6, 7, 6, 7, 11, 11, 6, 7, 11, 12, 11, 6, 10, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","correct labels:  [13, 13, 5, 6, 6, 6, 13, 13, 13, 13, 13, 13, 13, 13, 3, 13, 3, 13, 13, 13, 3, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","--------------------------------------------------------------------------\n","predicted labels:  [6, 1, 6, 5, 6, 1, 3, 11, 10, 6, 7, 0, 6, 11, 7, 3, 13, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","correct labels:  [13, 13, 13, 13, 13, 13, 13, 13, 5, 6, 13, 13, 3, 13, 13, 13, 13, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","--------------------------------------------------------------------------\n","predicted labels:  [6, 1, 9, 7, 9, 7, 5, 11, 7, 6, 11, 6, 6, 7, 7, 7, 6, 6, 6, 11, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","correct labels:  [13, 13, 13, 13, 11, 12, 13, 1, 2, 13, 13, 13, 13, 13, 13, 13, 1, 2, 13, 13, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","--------------------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["# Testset (try)"],"metadata":{"id":"bZxgU500beoo"}},{"cell_type":"code","source":["prediction = [['I', 'was', 'running', 'on', 'a', 'beach', 'of', 'Florida', 'State'],\n","['I', 'am', 'in', 'Los', 'Angeles'],\n","['On', 'Mountain', 'View', 'there', 'is', 'Google'],\n","['There', 'is', 'only', 'one', 'Michael', 'Jordan'],\n","['I', 'think', 'Kobe', 'was', 'the', 'greatest', 'Lakers', 'ever'],\n","['The', 'Bic', 'is', 'famous', 'for', 'pens'],\n","['Pasta', 'is', 'very', 'good', 'in', 'Italy'],\n","['Cassius', 'Marcellus', 'Clay', 'Jr', 'was', 'the', 'greatest', 'boxer', 'ever'],\n","['Yesterday', ',', 'it', 'was', 'raining', 'in', 'London', '.', 'Like', 'usual']]"],"metadata":{"id":"0k8ATIuBbeUE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#transform data so each phrase has the same length\n","def all_same_length_prediction(train, max):\n","  for i in range(0, len(train)):\n","    diff = max - len(train[i]) \n","    if diff > 0:\n","      for x in range(0, diff):\n","        train[i].append('pad')\n","\n","  return train"],"metadata":{"id":"Z5891RI5p5v8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = all_same_length_prediction(prediction, 10)"],"metadata":{"id":"Nk9o32NFqqaP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction"],"metadata":{"id":"5lZ5IoQosxw1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_to_indices_prediction(lista_train, w):\n","  word_indices = {}\n","  c = 0\n","\n","  for i in lista_train:\n","    indices = []\n","    for j in i:\n","      j = j.lower()\n","      try:\n","        indices.append(w[j])\n","      except:\n","        indices.append(1) #if the word isn't on dictionary\n","    word_indices[c] = indices\n","    c += 1\n","  return word_indices"],"metadata":{"id":"UPmyT_8iqPMP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = dataset_to_indices_prediction(prediction, word_to_indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMtd-KEuqynH","executionInfo":{"status":"ok","timestamp":1649195708573,"user_tz":-120,"elapsed":311,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"f5166f56-2c40-40ce-ae73-19086469cb2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NUOVA FRASE\n","NUOVA FRASE\n","NUOVA FRASE\n","NUOVA FRASE\n","NUOVA FRASE\n","NUOVA FRASE\n","NUOVA FRASE\n","NUOVA FRASE\n","NUOVA FRASE\n"]}]},{"cell_type":"code","source":["prediction"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7kA4VEPtDWT","executionInfo":{"status":"ok","timestamp":1649195712210,"user_tz":-120,"elapsed":363,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"e90b7a5a-fb2a-4830-a5fe-42df5d0ae650"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: [43, 17, 799, 15, 9, 1499, 5, 952, 94, 0],\n"," 1: [43, 915, 8, 798, 932, 0, 0, 0, 0, 0],\n"," 2: [15, 1613, 1141, 65, 16, 4363, 0, 0, 0, 0],\n"," 3: [65, 16, 93, 50, 787, 1752, 0, 0, 0, 0],\n"," 4: [43, 271, 9481, 17, 2, 2607, 4388, 663, 0, 0],\n"," 5: [2, 62527, 16, 1615, 12, 19999, 0, 0, 0, 0],\n"," 6: [12618, 16, 193, 221, 8, 933, 0, 0, 0, 0],\n"," 7: [45059, 44499, 4922, 16660, 17, 2, 2607, 8094, 663, 0],\n"," 8: [2859, 3, 22, 17, 24151, 8, 518, 4, 119, 3520]}"]},"metadata":{},"execution_count":137}]},{"cell_type":"code","source":["pred = {}\n","c = 0\n","for i in prediction:\n","  lista_pred = []\n","  for j in prediction[i]: \n","    lista_pred.append(torch.LongTensor(j))\n","  pred[c] = lista_pred\n","  c += 1"],"metadata":{"id":"CXxOyklsqbKo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred"],"metadata":{"id":"CXSbRFadubzI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test = {'1':[['I', 'O'], ['was', 'O'], ['running', 'O'], ['on', 'O'], ['a', 'O'], ['beach', 'O'], ['of', 'O'], ['Florida', 'B-LOC'], ['State', 'I-LOC']],\n","'2' : [['I', 'O'], ['am', 'O'], ['in', 'O'], ['Los', 'B-LOC'], ['Angeles', 'I-LOC']],\n","'3' : [['On', 'O'], ['Mountain', 'B-LOC'], ['View', 'I-LOC'], ['there', 'O'], ['is', 'O'], ['Google', 'B-CORP']],\n","'4' : [['There', 'O'], ['is', 'O'], ['only', 'O'], ['one', 'O'], ['Michael', 'B-PER'], ['Jordan', 'I-PER']],\n","'5' : [['I', 'O'], ['think', 'O'], ['Kobe', 'B-PER'], ['was', 'O'], ['the', 'O'], ['greatest', 'O'], ['Lakers', 'B-GRP'], ['ever', 'O']],\n","'6' : [['The', 'O'], ['Bic', 'B-CORP'], ['is', 'O'], ['famous', 'O'], ['for', 'O'], ['pens', 'B-PROD']],\n","'7' :[['Pasta', 'B-PROD'], ['is', 'O'], ['very', 'O'], ['good', 'O'], ['in', 'O'], ['Italy', 'B-LOC']],\n","'8' : [['Cassius', 'B-PER'], ['Marcellus', 'I-PER'], ['Clay', 'I-PER'], ['Jr', 'I-PER'], ['was', 'O'], ['the', 'O'], ['greatest', 'O'], ['boxer', 'O'], ['ever', 'O']],\n","'9' : [['Yesterday', 'O'], [',', 'O'], ['it', 'O'], ['was', 'O'], ['raining', 'O'], ['in', 'O'], ['London', 'B-LOC'], ['.', 'O'], ['Like', 'O'], ['usual', 'O']]}"],"metadata":{"id":"qAkXrmOHpbzQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test_creator(data, word_to_indices, label_to_indices):\n","  #lista, max = create_list(data)\n","  same_length = all_same_length(data, 10)\n","  word_indices = dataset_to_indices(same_length, word_to_indices)\n","  label_ind = label_index(same_length, label_to_indices)\n","\n","  data = {}\n","  for i in range(0, len(word_indices)):\n","    data[i]={'inputs': torch.LongTensor(word_indices[i]), 'outputs': torch.LongTensor(label_ind[i])}\n","\n","  return data"],"metadata":{"id":"opTaJjmqd5LU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = test_creator(test, word_to_indices, label_to_indices)"],"metadata":{"id":"CgpAHbtGhNKU","colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"status":"error","timestamp":1649447493221,"user_tz":-120,"elapsed":729,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"09c4d273-9047-4ab7-bc2c-9f46426cc6d1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-143-3f7b5871b93f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_to_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-b95fa9d9a643>\u001b[0m in \u001b[0;36mtest_creator\u001b[0;34m(data, word_to_indices, label_to_indices)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: new(): data must be a sequence (got dict)"]}]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"m9VYOK97pDnK"}},{"cell_type":"code","source":["class Trainer():\n","    \"\"\"Utility class to train and evaluate a model.\"\"\"\n","\n","    def __init__(\n","        self,\n","        model: nn.Module,\n","        loss_function,\n","        optimizer,\n","        label_vocab: indices_to_label,\n","        log_steps:int=10_000,\n","        log_level:int=2):\n","        \"\"\"\n","        Args:\n","            model: the model we want to train.\n","            loss_function: the loss_function to minimize.\n","            optimizer: the optimizer used to minimize the loss_function.\n","        \"\"\"\n","        self.model = model\n","        self.loss_function = loss_function\n","        self.optimizer = optimizer\n","\n","        self.label_vocab = label_vocab\n","        self.log_steps = log_steps\n","        self.log_level = log_level\n","        #self.label_vocab = label_vocab\n","\n","    def train(self, train_dataset, \n","              valid_dataset, \n","              epochs:int=1):\n","        \"\"\"\n","        Args:\n","            train_dataset: a Dataset or DatasetLoader instance containing\n","                the training instances.\n","            valid_dataset: a Dataset or DatasetLoader instance used to evaluate\n","                learning progress.\n","            epochs: the number of times to iterate over train_dataset.\n","\n","        Returns:\n","            avg_train_loss: the average training loss on train_dataset over\n","                epochs.\n","        \"\"\"\n","        assert epochs > 1 and isinstance(epochs, int)\n","        if self.log_level > 0:\n","            print('Training ...')\n","        train_loss = 0.0\n","        for epoch in range(epochs):\n","            if self.log_level > 0:\n","                print(' Epoch {:03d}'.format(epoch + 1))\n","\n","            epoch_loss = 0.0\n","            self.model.train()\n","\n","            # for each batch \n","            for step, sample in enumerate(train_dataset):\n","                inputs = sample['inputs']\n","                labels = sample['outputs']\n","                self.optimizer.zero_grad()\n","\n","                predictions = self.model(inputs)\n","                predictions = predictions.view(-1, predictions.shape[-1])\n","                labels = labels.view(-1)\n","                # labels  [[1,2,3], [18, 12, 3]] after the view(-1) [1,2,3, 18, 12, 3]\n","                \n","                sample_loss = self.loss_function(predictions, labels)\n","                sample_loss.backward()\n","                self.optimizer.step()\n","\n","                epoch_loss += sample_loss.tolist()\n","\n","                if self.log_level > 1 and step % self.log_steps == self.log_steps - 1:\n","                    print('\\t[E: {:2d} @ step {}] current avg loss = {:0.4f}'.format(epoch, step, epoch_loss / (step + 1)))\n","            \n","            avg_epoch_loss = epoch_loss / len(train_dataset)\n","            train_loss += avg_epoch_loss\n","            if self.log_level > 0:\n","                print('\\t[E: {:2d}] train loss = {:0.4f}'.format(epoch, avg_epoch_loss))\n","\n","            valid_loss = self.evaluate(valid_dataset)\n","            \n","            if self.log_level > 0:\n","                print('  [E: {:2d}] valid loss = {:0.4f}'.format(epoch, valid_loss))\n","\n","        if self.log_level > 0:\n","            print('... Done!')\n","        \n","        avg_epoch_loss = train_loss / epochs\n","        return avg_epoch_loss\n","    \n","\n","    def evaluate(self, valid_dataset):\n","        \"\"\"\n","        Args:\n","            valid_dataset: the dataset to use to evaluate the model.\n","\n","        Returns:\n","            avg_valid_loss: the average validation loss over valid_dataset.\n","        \"\"\"\n","        valid_loss = 0.0\n","        # set dropout to 0!! Needed when we are in inference mode.\n","        self.model.eval()\n","        with torch.no_grad():\n","            for sample in valid_dataset:\n","                inputs = sample['inputs']\n","                labels = sample['outputs']\n","\n","                predictions = self.model(inputs)\n","                predictions = predictions.view(-1, predictions.shape[-1])\n","                labels = labels.view(-1)\n","                print('LABRLS: ', labels.tolist())\n","                top_label_scores, top_label_indices = torch.max(predictions, -1)\n","                top_label_indices = top_label_indices.tolist()\n","                print('PREDICTION: ', top_label_indices)\n","                sample_loss = self.loss_function(predictions, labels)\n","                valid_loss += sample_loss.tolist()\n","        \n","        return valid_loss / len(valid_dataset)\n","\n","    def predict(self, x):\n","        \"\"\"\n","        Args:\n","            x: a tensor of indices.\n","        Returns: \n","            A list containing the predicted POS tag for each token in the\n","            input sentences.\n","        \"\"\"\n","        self.model.eval()\n","        with torch.no_grad():\n","            logits = self.model(x)\n","            predictions = torch.argmax(logits, -1)\n","            return logits, predictions\n","    \n","    "],"metadata":{"id":"kBDuvucDpGjN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","import torch.optim as optim\n","#window_size, window_shift = 100, 100\n","#device = \"cuda\"\n","training_data = load_dataset('/content/drive/MyDrive/data (1)/train.tsv')\n","dev_data = load_dataset('/content/drive/MyDrive/data (1)/dev.tsv')\n","trainingset = dataset_creator(training_data, word_to_indices, label_to_indices)\n","devset = dataset_creator(dev_data, word_to_indices, label_to_indices)\n","#testset = POSTaggingDataset(test_file, window_size, window_shift, device=device)\n","\n","#trainingset.index_dataset(vocabulary, label_vocabulary)\n","#devset.index_dataset(vocabulary, label_vocabulary)\n","#testset.index_dataset(vocabulary, label_vocabulary)\n","\n","train_dataset = DataLoader(trainingset, batch_size=128, shuffle=True)\n","valid_dataset = DataLoader(devset, batch_size=128, shuffle=False)\n","#test_dataset = DataLoader(testset, batch_size=128, shuffle=False)\n","\n","classifier = ClassifierModel(params)#.to(device)"],"metadata":{"id":"VUlopV0Vq8m8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649321772525,"user_tz":-120,"elapsed":7968,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"ca91b700-3839-4897-8101-a442f51e59d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  \n"]},{"output_type":"stream","name":"stdout","text":["<__main__.HParams object at 0x7fe3370c1cd0>\n"]}]},{"cell_type":"code","source":["lstm_singol = Trainer(\n","    model = classifier,\n","    loss_function = nn.CrossEntropyLoss(ignore_index=label_to_indices['PAD']),\n","    optimizer = optim.Adam(classifier.parameters()),\n","    label_vocab=indices_to_label\n",")"],"metadata":{"id":"uxCxX9aYq_fs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_singol.train(train_dataset, valid_dataset, 2)"],"metadata":{"id":"ky0WSw9krBwt","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1649321810356,"user_tz":-120,"elapsed":9462,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"9dd96eeb-6951-4925-8724-3ccb5ff14779"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training ...\n"," Epoch 001\n","INPUT:  tensor([[[-6.0386e-01, -6.6143e-02, -4.0672e-01,  ..., -4.8361e-01,\n","           4.4191e-01, -1.0129e+00],\n","         [-1.7906e+00, -3.0828e-01, -1.0645e+00,  ...,  3.0618e-01,\n","          -8.4928e-01,  7.2478e-01],\n","         [ 2.0122e-01, -5.8035e-01, -6.6098e-01,  ...,  7.2630e-01,\n","          -2.5641e-01,  2.7650e+00],\n","         ...,\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01],\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01],\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01]],\n","\n","        [[-1.8539e-01,  2.0697e-02, -6.4129e-01,  ...,  1.0500e+00,\n","          -5.8005e-01,  2.1595e-01],\n","         [ 1.0898e+00,  5.9133e-01, -1.6202e-01,  ...,  1.1750e+00,\n","           2.2873e-01, -1.3666e+00],\n","         [-1.7906e+00, -3.0828e-01, -1.0645e+00,  ...,  3.0618e-01,\n","          -8.4928e-01,  7.2478e-01],\n","         ...,\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01],\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01],\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01]],\n","\n","        [[ 2.2998e+00, -8.1582e-01,  1.4510e+00,  ..., -6.7407e-02,\n","           8.8398e-01,  2.2793e-03],\n","         [-4.0785e-01, -4.2040e-02,  3.2253e-02,  ..., -1.0814e+00,\n","           8.2922e-01, -1.9611e-01],\n","         [-1.3850e-01,  1.5072e+00, -1.9792e+00,  ..., -7.5359e-01,\n","          -6.1408e-03, -1.7128e+00],\n","         ...,\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01],\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01],\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01]],\n","\n","        ...,\n","\n","        [[-2.1026e+00, -6.4381e-02, -3.8884e-01,  ..., -1.1655e+00,\n","           1.0116e+00,  4.5171e-02],\n","         [-7.5390e-01,  8.6535e-02,  1.9009e+00,  ...,  3.7652e-01,\n","          -3.5471e-01, -7.7385e-01],\n","         [ 8.6733e-02, -6.2558e-02,  6.8353e-01,  ...,  1.3790e+00,\n","           6.5975e-01, -4.0652e-01],\n","         ...,\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01],\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01],\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01]],\n","\n","        [[-7.3310e-01, -4.4461e-01, -7.8722e-01,  ..., -6.1920e-01,\n","          -2.0952e+00,  5.3444e-01],\n","         [-5.9824e-01, -5.2621e-01, -4.8597e-01,  ...,  1.0419e+00,\n","          -1.0870e+00, -1.7160e+00],\n","         [ 2.8202e-01, -1.2082e-01,  1.2940e+00,  ...,  2.5120e-01,\n","          -7.8802e-01,  7.2538e-01],\n","         ...,\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01],\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01],\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01]],\n","\n","        [[-5.6411e-01, -2.1169e+00,  1.0443e+00,  ...,  1.0651e-01,\n","           1.2963e+00, -2.0411e-01],\n","         [-3.7238e-01,  6.0478e-01,  4.1641e-01,  ...,  7.2213e-01,\n","           4.5734e-01, -1.0923e+00],\n","         [-7.8449e-01,  1.8686e-01,  3.2023e-01,  ..., -7.8145e-01,\n","          -1.6871e-01,  1.3227e+00],\n","         ...,\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01],\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01],\n","         [ 2.4828e-02, -7.8006e-01, -9.7991e-01,  ...,  9.6870e-02,\n","           1.5476e-01,  3.4461e-01]]], grad_fn=<EmbeddingBackward0>)\n","INPUT:  tensor([[[-0.5992, -0.5252, -0.4870,  ...,  1.0429, -1.0860, -1.7170],\n","         [ 0.9483,  0.2765, -0.2758,  ...,  0.2974, -1.7207, -0.7327],\n","         [-0.4069, -0.0430,  0.0313,  ..., -1.0804,  0.8302, -0.1971],\n","         ...,\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436],\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436],\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436]],\n","\n","        [[-0.0553, -0.9465, -0.4837,  ..., -1.4339,  0.4055,  2.2909],\n","         [-0.2715, -0.3551,  0.6721,  ...,  1.3890, -0.7144, -0.4246],\n","         [ 1.4899,  1.3054,  0.8323,  ...,  0.6411,  0.9302,  0.9858],\n","         ...,\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436],\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436],\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436]],\n","\n","        [[ 0.0062, -1.0942, -1.0270,  ..., -0.3477,  1.0277, -0.2553],\n","         [ 1.5535,  0.1321,  1.8706,  ...,  0.5887,  0.4156, -1.7427],\n","         [ 1.8366, -0.4263, -1.0886,  ..., -0.6633,  1.4688,  1.2297],\n","         ...,\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436],\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436],\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436]],\n","\n","        ...,\n","\n","        [[-0.1395,  1.5062, -1.9802,  ..., -0.7526, -0.0051, -1.7138],\n","         [ 1.9403,  1.6528,  0.6786,  ...,  1.1749,  0.2620,  1.7102],\n","         [ 0.6334, -0.4068, -0.2006,  ...,  0.1103,  1.8137, -0.4899],\n","         ...,\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436],\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436],\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436]],\n","\n","        [[-0.1395,  1.5062, -1.9802,  ..., -0.7526, -0.0051, -1.7138],\n","         [-0.3775, -0.1377, -0.5807,  ..., -0.4467,  1.6734, -1.5105],\n","         [ 0.1050, -0.1390,  0.1954,  ...,  0.9696,  0.1224, -1.2055],\n","         ...,\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436],\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436],\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436]],\n","\n","        [[ 0.5884,  0.1437, -0.2255,  ..., -0.2982, -0.7522,  0.4520],\n","         [ 1.1232, -1.1363,  1.0172,  ..., -0.6598,  1.1755, -1.1458],\n","         [-1.3662, -0.3196,  0.4836,  ...,  0.7895, -0.5059,  1.9259],\n","         ...,\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436],\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436],\n","         [ 0.0238, -0.7811, -0.9809,  ...,  0.0979,  0.1558,  0.3436]]],\n","       grad_fn=<EmbeddingBackward0>)\n","INPUT:  tensor([[[-0.1404,  1.5053, -1.9811,  ..., -0.7516, -0.0041, -1.7148],\n","         [-0.4545,  0.7836,  1.2559,  ..., -0.0895, -1.0824, -0.6747],\n","         [ 0.6325, -0.4071, -0.2016,  ...,  0.1113,  1.8147, -0.4907],\n","         ...,\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427],\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427],\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427]],\n","\n","        [[ 0.2927,  2.3280, -1.2835,  ...,  0.5161, -0.9336, -0.4280],\n","         [-0.1133, -1.6069,  0.7217,  ..., -0.5320,  0.6044, -0.7400],\n","         [-2.5763, -0.7402,  0.5816,  ...,  1.1520, -1.3092, -0.5179],\n","         ...,\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427],\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427],\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427]],\n","\n","        [[ 1.9203, -0.0226, -0.0764,  ...,  0.9792,  0.2079,  0.0823],\n","         [ 0.2338,  0.8554,  0.5695,  ...,  1.0982,  0.6052,  0.1521],\n","         [-0.1404,  1.5053, -1.9811,  ..., -0.7516, -0.0041, -1.7148],\n","         ...,\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427],\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427],\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427]],\n","\n","        ...,\n","\n","        [[-0.5660, -2.1149,  1.0423,  ...,  0.1084,  1.2982, -0.2061],\n","         [-0.5002,  0.1243,  0.1806,  ..., -0.7140,  1.8318, -0.4405],\n","         [ 0.4132,  0.2708, -0.9934,  ..., -1.2804,  0.2130,  0.1250],\n","         ...,\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427],\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427],\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427]],\n","\n","        [[-2.1810, -0.4330,  0.7181,  ...,  0.6739,  0.4023, -0.1869],\n","         [ 0.0947,  0.3468, -1.9718,  ...,  1.0853,  0.2723, -0.8878],\n","         [ 0.8174, -1.1896,  0.6516,  ..., -0.3412, -0.8415,  0.3262],\n","         ...,\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427],\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427],\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427]],\n","\n","        [[-0.1404,  1.5053, -1.9811,  ..., -0.7516, -0.0041, -1.7148],\n","         [-0.1643,  0.2078, -1.1004,  ...,  2.4427,  1.8187,  1.5060],\n","         [-0.0918, -0.1305, -0.7029,  ...,  0.4255,  0.1054, -2.5600],\n","         ...,\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427],\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427],\n","         [ 0.0230, -0.7819, -0.9819,  ...,  0.0988,  0.1568,  0.3427]]],\n","       grad_fn=<EmbeddingBackward0>)\n","INPUT:  tensor([[[-0.4467,  0.3441,  1.1282,  ...,  0.0132,  2.1761,  0.0167],\n","         [-2.1741, -0.4814,  1.0443,  ...,  1.1314,  0.0039, -0.8029],\n","         [-0.1339, -0.0996,  0.6144,  ...,  0.4878, -0.4336,  1.5248],\n","         ...,\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418],\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418],\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418]],\n","\n","        [[ 0.2005, -0.8922, -1.2918,  ...,  1.5947,  0.5209, -0.9193],\n","         [ 0.0846, -0.0604,  0.6814,  ...,  1.3811,  0.6619, -0.4087],\n","         [ 0.6974,  0.7205, -0.1239,  ...,  0.9610, -0.0059,  0.5673],\n","         ...,\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418],\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418],\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418]],\n","\n","        [[-0.8583, -0.9700, -0.3390,  ...,  1.4248, -1.8032, -1.3453],\n","         [-1.2402,  1.1488, -1.4385,  ..., -1.8536,  0.3268, -0.1652],\n","         [ 0.0690,  1.1478, -0.4412,  ...,  0.9495, -0.2626, -0.0458],\n","         ...,\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418],\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418],\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418]],\n","\n","        ...,\n","\n","        [[-0.9653,  0.5436,  0.6365,  ..., -0.9097, -0.5836,  1.3268],\n","         [ 0.9640,  0.5836, -0.1222,  ..., -0.2504, -0.0382,  0.2341],\n","         [-1.0658,  1.4868,  0.8352,  ...,  0.7582, -0.9243,  0.9225],\n","         ...,\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418],\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418],\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418]],\n","\n","        [[-0.1412,  1.5045, -1.9821,  ..., -0.7507, -0.0032, -1.7157],\n","         [ 0.3426, -0.6513, -0.6379,  ...,  0.1349, -0.5767, -0.3130],\n","         [ 1.1748,  0.0264, -0.9787,  ...,  0.9278, -2.3809,  1.4025],\n","         ...,\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418],\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418],\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418]],\n","\n","        [[ 0.7412,  0.1021, -0.6340,  ...,  0.1429,  1.1382, -1.7558],\n","         [ 0.6317, -0.4078, -0.2024,  ...,  0.1121,  1.8156, -0.4916],\n","         [-0.1412,  1.5045, -1.9821,  ..., -0.7507, -0.0032, -1.7157],\n","         ...,\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418],\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418],\n","         [ 0.0221, -0.7827, -0.9828,  ...,  0.0996,  0.1578,  0.3418]]],\n","       grad_fn=<EmbeddingBackward0>)\n","INPUT:  tensor([[[-2.6873e-01, -1.0781e+00, -4.5285e-01,  ..., -1.0637e+00,\n","          -2.5026e+00, -4.8311e-01],\n","         [-6.2156e-01,  1.1925e+00,  1.6747e+00,  ...,  3.0693e-01,\n","           8.8260e-01,  1.1260e-02],\n","         [-2.5779e+00, -7.4166e-01,  5.7973e-01,  ...,  1.1538e+00,\n","          -1.3074e+00, -5.1975e-01],\n","         ...,\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01],\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01],\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01]],\n","\n","        [[-1.4208e-01,  1.5036e+00, -1.9830e+00,  ..., -7.4983e-01,\n","          -2.2367e-03, -1.7166e+00],\n","         [ 5.6925e-01, -5.1934e-01,  8.9591e-01,  ..., -1.0421e+00,\n","           3.7253e-01,  4.0584e-01],\n","         [ 1.6154e+00, -6.5999e-01, -1.6035e+00,  ...,  2.8550e-01,\n","          -3.9626e-01, -4.0835e-01],\n","         ...,\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01],\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01],\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01]],\n","\n","        [[-2.1245e+00,  8.5938e-01, -6.2033e-01,  ..., -1.5079e-01,\n","           1.2068e+00, -2.4812e-01],\n","         [-2.2754e+00, -1.0748e+00,  7.8667e-01,  ..., -1.1272e+00,\n","           1.3946e-01, -1.9618e+00],\n","         [-5.7913e-02, -1.0484e+00, -1.1718e+00,  ...,  6.3449e-01,\n","          -1.3182e-01, -1.4575e+00],\n","         ...,\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01],\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01],\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01]],\n","\n","        ...,\n","\n","        [[-4.9778e-01,  1.0455e+00,  7.2617e-01,  ..., -8.3428e-01,\n","           1.4291e+00, -2.5604e-01],\n","         [ 3.0269e-01,  2.6388e-01,  7.2526e-02,  ...,  1.0862e+00,\n","          -8.3447e-01,  6.7902e-01],\n","         [-1.1960e+00,  1.8731e+00,  2.0752e-01,  ...,  1.1400e+00,\n","           2.0271e+00,  4.2040e-01],\n","         ...,\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01],\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01],\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01]],\n","\n","        [[-7.3670e-01, -4.4829e-01, -7.9095e-01,  ..., -6.1524e-01,\n","          -2.0913e+00,  5.3064e-01],\n","         [-1.4208e-01,  1.5036e+00, -1.9830e+00,  ..., -7.4983e-01,\n","          -2.2367e-03, -1.7166e+00],\n","         [-2.7574e-01, -7.8437e-01,  5.5182e-02,  ...,  3.8498e-01,\n","           1.2475e+00,  8.4371e-01],\n","         ...,\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01],\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01],\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01]],\n","\n","        [[-5.6773e-01, -2.1145e+00,  1.0405e+00,  ...,  1.1013e-01,\n","           1.3001e+00, -2.0789e-01],\n","         [-1.7484e+00, -1.1265e+00, -2.0541e-01,  ..., -1.9514e+00,\n","          -6.7015e-02, -1.0397e+00],\n","         [ 1.4233e+00,  1.1219e+00, -1.4013e+00,  ...,  9.5614e-01,\n","           1.6053e+00, -8.5649e-01],\n","         ...,\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01],\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01],\n","         [ 2.1251e-02, -7.8348e-01, -9.8377e-01,  ...,  1.0052e-01,\n","           1.5876e-01,  3.4080e-01]]], grad_fn=<EmbeddingBackward0>)\n","INPUT:  tensor([[[-5.8696e-02, -9.4576e-01, -4.8729e-01,  ..., -1.4305e+00,\n","           4.0914e-01,  2.2876e+00],\n","         [ 7.1309e-01, -1.8616e-01, -2.9588e-02,  ..., -2.3812e-01,\n","           3.8724e-01,  2.6780e-01],\n","         [ 1.3870e+00, -2.9863e-01,  1.0213e+00,  ...,  2.6587e+00,\n","          -1.0415e-01, -1.0188e+00],\n","         ...,\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01],\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01],\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01]],\n","\n","        [[-1.8457e+00, -9.3354e-01, -2.6007e-01,  ...,  1.1107e-02,\n","          -5.0901e-01,  5.8081e-01],\n","         [-8.6270e-01, -9.2058e-01,  5.1992e-01,  ...,  3.8993e-01,\n","          -6.9292e-01,  1.1079e-01],\n","         [ 1.9676e-01, -5.8490e-01, -6.6567e-01,  ...,  7.2944e-01,\n","          -2.5182e-01,  2.7604e+00],\n","         ...,\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01],\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01],\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01]],\n","\n","        [[ 2.6389e-01,  1.2064e-01,  1.1917e+00,  ..., -1.4475e+00,\n","          -1.0846e+00,  4.0287e-02],\n","         [ 5.2012e-02,  1.5435e-01,  2.2191e+00,  ...,  5.8536e-01,\n","          -7.7362e-02,  3.8839e-01],\n","         [-1.7931e+00, -7.9410e-01,  1.1380e+00,  ...,  2.0758e-01,\n","           2.2541e-01, -2.6158e+00],\n","         ...,\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01],\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01],\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01]],\n","\n","        ...,\n","\n","        [[-5.6858e-01, -2.1152e+00,  1.0396e+00,  ...,  1.1096e-01,\n","           1.3010e+00, -2.0878e-01],\n","         [-2.7475e-01, -3.5848e-01,  6.6833e-01,  ...,  1.3923e+00,\n","          -7.1038e-01, -4.2806e-01],\n","         [ 2.7211e-01, -8.7613e-01,  6.5138e-01,  ...,  2.5933e-01,\n","          -8.8380e-01,  4.3412e-01],\n","         ...,\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01],\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01],\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01]],\n","\n","        [[-1.4297e-01,  1.5028e+00, -1.9839e+00,  ..., -7.4894e-01,\n","          -1.2757e-03, -1.7176e+00],\n","         [ 8.2297e-01, -1.3667e-01,  8.3898e-01,  ...,  1.3113e+00,\n","           6.7807e-01,  4.7600e-01],\n","         [-2.7475e-01, -3.5848e-01,  6.6833e-01,  ...,  1.3923e+00,\n","          -7.1038e-01, -4.2806e-01],\n","         ...,\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01],\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01],\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01]],\n","\n","        [[-1.4297e-01,  1.5028e+00, -1.9839e+00,  ..., -7.4894e-01,\n","          -1.2757e-03, -1.7176e+00],\n","         [-2.5266e-01, -6.9063e-01,  1.0186e+00,  ...,  2.0506e-01,\n","           3.2872e-01, -1.4434e-01],\n","         [-1.3455e+00,  5.2649e-02,  1.1305e+00,  ..., -1.6515e+00,\n","          -1.9082e-02, -6.9853e-01],\n","         ...,\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01],\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01],\n","         [ 2.0326e-02, -7.8437e-01, -9.8474e-01,  ...,  1.0145e-01,\n","           1.5970e-01,  3.3982e-01]]], grad_fn=<EmbeddingBackward0>)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-4a6b52f43ac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm_singol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-46-93b88ae7bc66>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, valid_dataset, epochs)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-44-7e35419c07c5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'INPUT: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 692\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["test_dataset = DataLoader(test_data, batch_size=128, shuffle=False)\n","lstm_singol.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"id":"wIVDjHtQpC5b","executionInfo":{"status":"error","timestamp":1649447481975,"user_tz":-120,"elapsed":443,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"d3fdad5c-af97-4bd6-9966-47d837a69d17"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-142-9ec338769cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlstm_singol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"]}]},{"cell_type":"markdown","source":["# Bi directional LSTM"],"metadata":{"id":"_R2tCb6t43LQ"}},{"cell_type":"code","source":["params.bidirectional=True\n","params.num_layers=2"],"metadata":{"id":"cVoZJig74z6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bilstm_classifier = ClassifierModel(params)#.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FMeeHNjA47vi","executionInfo":{"status":"ok","timestamp":1649321815163,"user_tz":-120,"elapsed":483,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"64a1c776-0291-4a72-b5a8-7f0cd62aeac3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.HParams object at 0x7fe3370c1cd0>\n"]}]},{"cell_type":"code","source":["bilstm_trainer = Trainer(\n","    model = bilstm_classifier,\n","    loss_function = nn.CrossEntropyLoss(ignore_index=label_to_indices['PAD']),\n","    optimizer = optim.Adam(bilstm_classifier.parameters()),\n","    label_vocab=indices_to_label\n",")"],"metadata":{"id":"69GgXU6U5EzZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bilstm_trainer.train(train_dataset, valid_dataset, 2)"],"metadata":{"id":"ARvMdIZl5Ff8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset = DataLoader(test_data, batch_size=128, shuffle=False)\n","bilstm_trainer.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fDgL9BeWveKx","executionInfo":{"status":"ok","timestamp":1649278303746,"user_tz":-120,"elapsed":313,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"8bb3e7c1-487c-4d8d-8bbf-487891e6dccb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LABRLS:  [13, 13, 13, 13, 13, 13, 13, 3, 4, 0, 13, 13, 13, 3, 4, 0, 0, 0, 0, 0, 13, 3, 4, 13, 13, 7, 0, 0, 0, 0, 13, 13, 13, 13, 1, 2, 0, 0, 0, 0, 13, 13, 1, 13, 13, 13, 5, 13, 0, 0, 13, 7, 13, 13, 13, 9, 0, 0, 0, 0, 9, 13, 13, 13, 13, 3, 0, 0, 0, 0, 1, 2, 2, 2, 13, 13, 13, 13, 13, 0, 13, 13, 13, 13, 13, 13, 3, 13, 13, 13]\n","PREDICTION:  [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 2, 13, 13, 13, 13, 13, 13, 13, 13, 13, 2, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 2, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n"]},{"output_type":"execute_result","data":{"text/plain":["1.123106837272644"]},"metadata":{},"execution_count":202}]},{"cell_type":"markdown","source":["# Save and Load model"],"metadata":{"id":"9GY6fPeuid04"}},{"cell_type":"code","source":["#save\n","torch.save(model, PATH)"],"metadata":{"id":"0Efd9xAjii4J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load\n","# Model class must be defined somewhere\n","model = torch.load(PATH)\n","model.eval()"],"metadata":{"id":"suyf3nflindy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LSTM without stopwords"],"metadata":{"id":"SBEmYL3BBO1u"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","\n","list_punct = [',', '!', '?', '\"', '.', ';', ':', '-', '_', '|', '\\'', '/', '%', '&', '#', '+', '*', '^', '$', '(', ')', '[', ']', '{', '}', '<', '>', '=']\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","print(stopwords.words('english')) #print stop words\n","\n","for i in stopwords.words('english'):\n","  list_punct.append(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IU3raimBBqs9","executionInfo":{"status":"ok","timestamp":1649168698455,"user_tz":-120,"elapsed":479,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"3a28e3a6-f809-4503-bf9d-15fe2ba2e1d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"]}]},{"cell_type":"code","source":["#dataset\n","def remove_stopwords(data):\n","  max = 0\n","  for i in data:\n","    length = 0\n","    for j in data[i]:\n","      length += 1\n","      if j[0] in list_punct:\n","        data[i].pop(length - 1)\n","    if max < length:\n","      max = length\n","  return data, max"],"metadata":{"id":"3kNU3r1iBTOR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lista[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_T2BgvWKg6E","executionInfo":{"status":"ok","timestamp":1649169582734,"user_tz":-120,"elapsed":7,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"8c7fc7fc-c6ae-4006-d138-d906f89b653f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['lies', 'O'],\n"," ['approximately', 'O'],\n"," ['north', 'O'],\n"," ['east', 'O'],\n"," ['bolesławiec', 'B-LOC'],\n"," ['west', 'O'],\n"," ['regional', 'O'],\n"," ['capital', 'O'],\n"," ['wrocław', 'B-LOC']]"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["def dataset_creator_stopwords(data, word_to_indices, label_to_indices):\n","  lista, max = create_list(data)\n","  lista, max = remove_stopwords(lista)\n","  print(max)\n","  lista, max = remove_stopwords(lista)\n","  print(max)\n","  same_length = all_same_length(lista, max)\n","  word_indices = dataset_to_indices(same_length, word_to_indices)\n","  label_ind = label_index(same_length, label_to_indices)\n","\n","  data = {}\n","  for i in range(0, len(word_indices)):\n","    data[i]={'inputs': torch.LongTensor(word_indices[i]), 'outputs': torch.LongTensor(label_ind[i])}\n","\n","  return data"],"metadata":{"id":"sWk9sEUzG9HE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset_stopwords[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Kpx2wtBHlXn","executionInfo":{"status":"ok","timestamp":1649169839832,"user_tz":-120,"elapsed":315,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"50cc2118-8a3f-409d-aa2f-541dd7dbb320"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'inputs': tensor([  2347,   2129,    195,    324, 149550,    261,    912,    353,  32378,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0]),\n"," 'outputs': tensor([13, 13, 13, 13,  3, 13, 13, 13,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0])}"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["#model\n","\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","#window_size, window_shift = 100, 100\n","#device = \"cuda\"\n","\n","training_data_stopword = load_dataset('/content/drive/MyDrive/data (1)/train.tsv')\n","dev_data_stopwords = load_dataset('/content/drive/MyDrive/data (1)/dev.tsv')\n","\n","train_dataset_stopwords = dataset_creator_stopwords(training_data_stopword, word_to_indices, label_to_indices)\n","\n","devset_stopwords = dataset_creator_stopwords(dev_data_stopwords, word_to_indices, label_to_indices)\n","#testset = POSTaggingDataset(test_file, window_size, window_shift, device=device)\n","\n","#trainingset.index_dataset(vocabulary, label_vocabulary)\n","#devset.index_dataset(vocabulary, label_vocabulary)\n","#testset.index_dataset(vocabulary, label_vocabulary)\n","\n","train_dataset_stopwords = DataLoader(train_dataset_stopwords, batch_size=128, shuffle=True)\n","valid_dataset_stopwords = DataLoader(devset_stopwords, batch_size=128, shuffle=False)\n","#test_dataset = DataLoader(testset, batch_size=128, shuffle=False)\n","\n","classifier_stopwords = ClassifierModel(params)#.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npBMELkQV7LM","executionInfo":{"status":"ok","timestamp":1649172710981,"user_tz":-120,"elapsed":9284,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"9019e0b8-dd32-4c88-b89e-4fb02f4e4613"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  if __name__ == '__main__':\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  if __name__ == '__main__':\n"]},{"output_type":"stream","name":"stdout","text":["30\n","28\n","25\n","21\n","<__main__.HParams object at 0x7f01b1a57950>\n"]}]},{"cell_type":"code","source":["trainer = Trainer(\n","    model = classifier_stopwords,\n","    loss_function = nn.CrossEntropyLoss(ignore_index=label_to_indices['PAD']),\n","    optimizer = optim.Adam(classifier_stopwords.parameters()),\n","    label_vocab=indices_to_label\n",")"],"metadata":{"id":"e6Adku0DWpiC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train(train_dataset_stopwords, valid_dataset_stopwords, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nx49q3BpWwAY","executionInfo":{"status":"ok","timestamp":1649173525605,"user_tz":-120,"elapsed":728611,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"1e4dfdf5-8165-45da-85bb-0e5ac29285b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training ...\n"," Epoch 001\n","\t[E:  0] train loss = 1.5786\n","  [E:  0] valid loss = 1.4099\n"," Epoch 002\n","\t[E:  1] train loss = 1.3585\n","  [E:  1] valid loss = 1.3157\n"," Epoch 003\n","\t[E:  2] train loss = 1.2484\n","  [E:  2] valid loss = 1.2243\n"," Epoch 004\n","\t[E:  3] train loss = 1.1534\n","  [E:  3] valid loss = 1.1693\n"," Epoch 005\n","\t[E:  4] train loss = 1.0748\n","  [E:  4] valid loss = 1.1273\n"," Epoch 006\n","\t[E:  5] train loss = 1.0092\n","  [E:  5] valid loss = 1.0946\n"," Epoch 007\n","\t[E:  6] train loss = 0.9542\n","  [E:  6] valid loss = 1.0812\n"," Epoch 008\n","\t[E:  7] train loss = 0.9046\n","  [E:  7] valid loss = 1.0680\n"," Epoch 009\n","\t[E:  8] train loss = 0.8630\n","  [E:  8] valid loss = 1.0584\n"," Epoch 010\n","\t[E:  9] train loss = 0.8225\n","  [E:  9] valid loss = 1.0563\n","... Done!\n"]},{"output_type":"execute_result","data":{"text/plain":["1.0967298052812877"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","source":["# CNN with embeds"],"metadata":{"id":"bHA1FTW1Iozb"}},{"cell_type":"code","source":["training_data = load_dataset('/content/drive/MyDrive/data (1)/train.tsv')\n","lista, max = create_list(training_data)"],"metadata":{"id":"0_rLzD0kIt1o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649324765560,"user_tz":-120,"elapsed":5413,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"70d61966-dc62-410d-96a5-91bd19147493"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  \"\"\"Entry point for launching an IPython kernel.\n"]}]},{"cell_type":"code","source":["def emebd_words(data):\n","  dic = {}\n","  unk = wv['unk']\n","  unk = torch.from_numpy(unk)\n","  for i in data:\n","    lista = []\n","    for j in data[i]:\n","      try:\n","        e = wv[j[0]]\n","        t = torch.from_numpy(e)\n","        lista.append([t, j[1]])\n","      except:\n","        lista.append([unk, j[1]])\n","    dic[i] = lista\n","  return dic"],"metadata":{"id":"htt1eAl4IxNR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeds = emebd_words(lista)"],"metadata":{"id":"EnJ2-6hoTCuh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649321272391,"user_tz":-120,"elapsed":1640,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"0fcee3ff-9f1b-4de2-8f0c-2ca56357580c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n","  after removing the cwd from sys.path.\n"]}]},{"cell_type":"code","source":["def all_same_length_embeds(train, max):\n","  pad = torch.zeros(300)\n","  for i in train:\n","    diff = max - len(train[i]) \n","    if diff > 0:\n","      for x in range(0, diff):\n","        train[i].append([pad, 'PAD'])\n","\n","  return train"],"metadata":{"id":"xmWiSn8nUxBa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeds = all_same_length_embeds(embeds, max)"],"metadata":{"id":"aDPYhaXnVm5C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_to_embeds(lista_train):\n","  dic = {}\n","  c = 0\n","\n","  for i in lista_train:\n","    lista = []\n","    for j in lista_train[i]:\n","      lista.append(j[0])\n","    dic[c] = lista\n","    c += 1\n","  return dic"],"metadata":{"id":"qn2wQYrwfS1l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_to_indices_cnn = {'PAD' : -100, 'B-PER' : 1,'I-PER' : 2,'B-LOC' : 3,'I-LOC' : 4,'B-GRP' : 5,'I-GRP' : 6,'B-CORP' : 7,'I-CORP' : 8,'B-PROD' : 9,'I-PROD' : 10,'B-CW' : 11,'I-CW' : 12,'O' : 13}"],"metadata":{"id":"Yhvy39m4vV00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_creator_cnn(data, label_to_indices):\n","  lista, max = create_list(data)\n","  embeds = emebd_words(lista)\n","  same_length = all_same_length_embeds(embeds, max)\n","  word_indices = dataset_to_embeds(same_length)\n","  label_ind, count_classes = label_index(embeds, label_to_indices)\n","\n","  data = {}\n","  for i in range(0, len(same_length)):\n","    data[i]={'inputs': torch.stack(word_indices[i]), 'outputs': torch.LongTensor(label_ind[i])}\n","\n","  return data, count_classes"],"metadata":{"id":"fE1ICkxddIGr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","import torch.optim as optim\n","#window_size, window_shift = 100, 100\n","#device = \"cuda\"\n","training_data_cnn = load_dataset('/content/drive/MyDrive/data (1)/train.tsv')\n","dev_data_cnn = load_dataset('/content/drive/MyDrive/data (1)/dev.tsv')\n","trainingset_cnn, count_classes_train = dataset_creator_cnn(training_data_cnn, label_to_indices)\n","devset_cnn, count_classes_devset = dataset_creator_cnn(dev_data_cnn, label_to_indices)\n","#testset = POSTaggingDataset(test_file, window_size, window_shift, device=device)\n","\n","param_classes(count_classes_train, params)\n","\n","#trainingset.index_dataset(vocabulary, label_vocabulary)\n","#devset.index_dataset(vocabulary, label_vocabulary)\n","#testset.index_dataset(vocabulary, label_vocabulary)\n","\n","train_dataset_cnn = DataLoader(trainingset_cnn, batch_size=128, shuffle=True)\n","valid_dataset_cnn = DataLoader(devset_cnn, batch_size=128, shuffle=False)\n","#test_dataset = DataLoader(testset, batch_size=128, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BMFm47IOc7mv","executionInfo":{"status":"ok","timestamp":1649454762583,"user_tz":-120,"elapsed":8922,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"fe27c86f-82f2-4a40-911f-a2697ee4d48a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  \n"]}]},{"cell_type":"code","source":["params.class_vector"],"metadata":{"id":"n8sEMGUFar8t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Bilstm with Lstm"],"metadata":{"id":"Zbp8htRXJ57a"}},{"cell_type":"code","source":["def param_classes(count_classes, params):\n","  sum = 0\n","  vec = []\n","  for i in count_classes:\n","    sum += count_classes[i]\n","  for i in count_classes:\n","    a = count_classes[i]/sum\n","    #vec.append(1.0/a)\n","    vec.append(1-a)\n","  for i in range(2, len(vec)):\n","    vec[i] *= 1.5\n","  params.class_vector = torch.tensor(vec)\n"],"metadata":{"id":"u-RW-tvptQn1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_creator_cnn_test(data, label_to_indices):\n","  #lista, max = create_list(data)\n","  max = 10\n","  embeds = emebd_words(data)\n","  same_length = all_same_length_embeds(embeds, max)\n","  word_indices = dataset_to_embeds(same_length)\n","  label_ind, c = label_index(embeds, label_to_indices)\n","\n","  data = {}\n","  for i in range(0, len(same_length)):\n","    data[i]={'inputs': torch.stack(word_indices[i]), 'outputs': torch.LongTensor(label_ind[i])}\n","\n","  return data"],"metadata":{"id":"--y7JGATY7Hf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_cnn = dataset_creator_cnn_test(test, label_to_indices)"],"metadata":{"id":"I3QJRiZ8Ya6L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(test_cnn[0]['inputs'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8FyIj4ggZxwm","executionInfo":{"status":"ok","timestamp":1649449435187,"user_tz":-120,"elapsed":6,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"e8ffacd9-8336-4dfe-bf42-6fdfc55055a4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["300"]},"metadata":{},"execution_count":174}]},{"cell_type":"code","source":["class ClassifierModel(nn.Module):\n","    # we provide the hyperparameters as input\n","    def __init__(self, hparams):\n","        super(ClassifierModel, self).__init__()\n","        \n","        #self.word_embedding = nn.Embedding(hparams.vocab_size, hparams.embedding_dim)\n","        \n","\n","        # LSTM layer: an LSTM neural network that process the input text\n","        # (encoded with word embeddings) from left to right and outputs \n","        # a new **contextual** representation of each word that depend\n","        # on the preciding words.\n","        self.lstm1 = nn.LSTM(hparams.embedding_dim, hparams.hidden_dim, \n","                            bidirectional=hparams.bidirectional,\n","                            num_layers=hparams.num_layers, \n","                            dropout = hparams.dropout if hparams.num_layers > 1 else 0)\n","        \n","        lstm_output_dim = hparams.hidden_dim * 2\n","        \n","        self.pool1 = torch.nn.MaxPool1d(5, stride=2, padding=2) #AvgPool1d\n","        self.pool2 = torch.nn.AvgPool1d(5, stride=2, padding=2) #AvgPool1d\n","\n","\n","        self.fc1 = nn.Linear(lstm_output_dim, 1200)\n","        self.fc2 = nn.Linear(600, 1500)\n","        #self.fc3 = nn.Linear(2000, 1500)\n","        #self.fc4 = nn.Linear(1500, 900)\n","\n","        self.lstm2 = nn.LSTM(lstm_output_dim, hparams.hidden_dim, \n","                            bidirectional=False,\n","                            num_layers=1, \n","                            dropout = 0)\n","        # Hidden layer: transforms the input value/scalar into\n","        # a hidden vector representation.\n","        #lstm_output_dim = hparams.hidden_dim\n","\n","        # During training, randomly zeroes some of the elements of the \n","        # input tensor with probability hparams.dropout using samples \n","        # from a Bernoulli distribution. Each channel will be zeroed out \n","        # independently on every forward call.\n","        # This has proven to be an effective technique for regularization and \n","        # preventing the co-adaptation of neurons\n","        self.dropout = nn.Dropout(hparams.dropout)\n","        self.classifier = nn.Linear(600, hparams.num_classes) #lstm_output_dim\n","\n","    \n","    def forward(self, x):\n","        #embeddings = self.word_embedding(x)\n","        #embeddings = self.dropout(embeddings)\n","        #print('INPUT: ', x.size())\n","        o, (h, c) = self.lstm1(x)\n","        #print('lstm1: ', o.size())\n","        #o = self.dropout(o)\n","        o = self.fc1(o)\n","        o = self.pool1(o)\n","        o = self.dropout(o)\n","        \n","        #print('fc1: ', o.size())\n","        #o, (h, c) = self.lstm2(o)\n","        #o = self.dropout(o)\n","        #print('lstm2: ', o.size())\n","        output = self.classifier(o)\n","        return output\n","\n","        "],"metadata":{"id":"YOauDYaxKEeP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Trainer():\n","    \"\"\"Utility class to train and evaluate a model.\"\"\"\n","\n","    def __init__(\n","        self,\n","        model: nn.Module,\n","        loss_function,\n","        optimizer,\n","        label_vocab: indices_to_label,\n","        log_steps:int=10_000,\n","        log_level:int=2):\n","        \"\"\"\n","        Args:\n","            model: the model we want to train.\n","            loss_function: the loss_function to minimize.\n","            optimizer: the optimizer used to minimize the loss_function.\n","        \"\"\"\n","        self.model = model\n","        self.loss_function = loss_function\n","        self.optimizer = optimizer\n","\n","        self.label_vocab = label_vocab\n","        self.log_steps = log_steps\n","        self.log_level = log_level\n","        #self.label_vocab = label_vocab\n","\n","    def train(self, train_dataset, \n","              valid_dataset, \n","              epochs:int=1):\n","        \"\"\"\n","        Args:\n","            train_dataset: a Dataset or DatasetLoader instance containing\n","                the training instances.\n","            valid_dataset: a Dataset or DatasetLoader instance used to evaluate\n","                learning progress.\n","            epochs: the number of times to iterate over train_dataset.\n","\n","        Returns:\n","            avg_train_loss: the average training loss on train_dataset over\n","                epochs.\n","        \"\"\"\n","        assert epochs > 1 and isinstance(epochs, int)\n","        if self.log_level > 0:\n","            print('Training ...')\n","        train_loss = 0.0\n","        for epoch in range(epochs):\n","            if self.log_level > 0:\n","                print(' Epoch {:03d}'.format(epoch + 1))\n","\n","            epoch_loss = 0.0\n","            self.model.train()\n","\n","            # for each batch \n","            for step, sample in enumerate(train_dataset):\n","                inputs = sample['inputs']\n","                labels = sample['outputs']\n","                self.optimizer.zero_grad()\n","\n","                predictions = self.model(inputs)\n","                predictions = predictions.view(-1, predictions.shape[-1])\n","                labels = labels.view(-1)\n","                # labels  [[1,2,3], [18, 12, 3]] after the view(-1) [1,2,3, 18, 12, 3]\n","                \n","                sample_loss = self.loss_function(predictions, labels)\n","                sample_loss.backward()\n","                self.optimizer.step()\n","\n","                epoch_loss += sample_loss.tolist()\n","\n","                if self.log_level > 1 and step % self.log_steps == self.log_steps - 1:\n","                    print('\\t[E: {:2d} @ step {}] current avg loss = {:0.4f}'.format(epoch, step, epoch_loss / (step + 1)))\n","            \n","            avg_epoch_loss = epoch_loss / len(train_dataset)\n","            train_loss += avg_epoch_loss\n","            if self.log_level > 0:\n","                print('\\t[E: {:2d}] train loss = {:0.4f}'.format(epoch, avg_epoch_loss))\n","\n","            valid_loss = self.evaluate(valid_dataset)\n","            \n","            if self.log_level > 0:\n","                print('  [E: {:2d}] valid loss = {:0.4f}'.format(epoch, valid_loss))\n","\n","        if self.log_level > 0:\n","            print('... Done!')\n","        \n","        avg_epoch_loss = train_loss / epochs\n","        return avg_epoch_loss\n","    \n","\n","    def evaluate(self, valid_dataset):\n","        \"\"\"\n","        Args:\n","            valid_dataset: the dataset to use to evaluate the model.\n","\n","        Returns:\n","            avg_valid_loss: the average validation loss over valid_dataset.\n","        \"\"\"\n","        valid_loss = 0.0\n","        # set dropout to 0!! Needed when we are in inference mode.\n","        self.model.eval()\n","        with torch.no_grad():\n","            for sample in valid_dataset:\n","                inputs = sample['inputs']\n","                labels = sample['outputs']\n","\n","                predictions = self.model(inputs)\n","                predictions = predictions.view(-1, predictions.shape[-1])\n","                labels = labels.view(-1)\n","                #print('LABRLS: ', labels.tolist())\n","                top_label_scores, top_label_indices = torch.max(predictions, -1)\n","                top_label_indices = top_label_indices.tolist()\n","                #print('PREDICTION: ', top_label_indices)\n","                sample_loss = self.loss_function(predictions, labels)\n","                valid_loss += sample_loss.tolist()\n","                f1_score1 = f1_score(labels.data, top_label_indices, average=\"macro\")\n","                print(f1_score1)\n","        \n","        return valid_loss / len(valid_dataset)\n","\n","    def predict(self, x):\n","        \"\"\"\n","        Args:\n","            x: a tensor of indices.\n","        Returns: \n","            A list containing the predicted POS tag for each token in the\n","            input sentences.\n","        \"\"\"\n","        self.model.eval()\n","        with torch.no_grad():\n","            logits = self.model(x)\n","            predictions = torch.argmax(logits, -1)\n","            return logits, predictions\n","    \n","    "],"metadata":{"id":"YLK-dEh3J_XF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class HParams():\n","    vocab_size = len(words)\n","    hidden_dim = 128\n","    embedding_dim = 300\n","    num_classes = len(indices_to_label)\n","    bidirectional = True\n","    num_layers = 3\n","    dropout = 0.05\n","    embeddings = None\n","    class_vector = []\n","params = HParams()"],"metadata":{"id":"g-luDjblLP3V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bilstm_classifier = ClassifierModel(params)#.cuda()"],"metadata":{"id":"ZoBHQs_yLar9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bilstm_trainer = Trainer(\n","    model = bilstm_classifier,\n","    loss_function = nn.CrossEntropyLoss(weight=params.class_vector, ignore_index=label_to_indices['PAD']),\n","    optimizer = optim.Adam(bilstm_classifier.parameters()),\n","    label_vocab=indices_to_label\n",")"],"metadata":{"id":"DZEfzBjXLgYh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bilstm_trainer.train(train_dataset_cnn, valid_dataset_cnn, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZW7BOk1JLlzz","executionInfo":{"status":"ok","timestamp":1649456227175,"user_tz":-120,"elapsed":1446703,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"5ece47a8-25fe-4a7d-fd2e-5cbef8a768ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training ...\n"," Epoch 001\n","\t[E:  0] train loss = 1.3506\n","0.12794018270452417\n","0.11769659023250402\n","0.12654563029153748\n","0.12196901962579436\n","0.10997963557457589\n","0.1187416858557798\n","  [E:  0] valid loss = 1.0761\n"," Epoch 002\n","\t[E:  1] train loss = 0.9655\n","0.28254039943058407\n","0.24330171179775498\n","0.27883331701141\n","0.25801880809970146\n","0.19819696316593463\n","0.21272630883331273\n","  [E:  1] valid loss = 0.8827\n"," Epoch 003\n","\t[E:  2] train loss = 0.8318\n","0.35412512780665795\n","0.36340429609828895\n","0.3730265856052383\n","0.32659611926056126\n","0.29414175175866575\n","0.30961742560564876\n","  [E:  2] valid loss = 0.8029\n"," Epoch 004\n","\t[E:  3] train loss = 0.7728\n","0.387481789840235\n","0.39299200616117574\n","0.39011493255263746\n","0.34727206931367416\n","0.30450078054001894\n","0.3192780872137883\n","  [E:  3] valid loss = 0.7739\n"," Epoch 005\n","\t[E:  4] train loss = 0.7397\n","0.4125511449168884\n","0.4076857504479348\n","0.3957158509048394\n","0.38227479821733296\n","0.3254958850747035\n","0.3369789415954724\n","  [E:  4] valid loss = 0.7567\n"," Epoch 006\n","\t[E:  5] train loss = 0.7134\n","0.42170726893726573\n","0.41103770568093095\n","0.41576220257358604\n","0.3949578069441847\n","0.3320449884768893\n","0.3566787699338391\n","  [E:  5] valid loss = 0.7424\n"," Epoch 007\n","\t[E:  6] train loss = 0.6898\n","0.43856603936923566\n","0.4237736483685784\n","0.42616988824242863\n","0.39053374905955274\n","0.3621793399075618\n","0.38404514594891437\n","  [E:  6] valid loss = 0.7310\n"," Epoch 008\n","\t[E:  7] train loss = 0.6739\n","0.44665866946945076\n","0.4427199300162314\n","0.418711814350796\n","0.3983887909720107\n","0.3436486633779653\n","0.3530970128456505\n","  [E:  7] valid loss = 0.7192\n"," Epoch 009\n","\t[E:  8] train loss = 0.6573\n","0.45934809829643297\n","0.43852839735416077\n","0.42799991374709423\n","0.4040219220889911\n","0.3665302280964344\n","0.36177590655046404\n","  [E:  8] valid loss = 0.7236\n"," Epoch 010\n","\t[E:  9] train loss = 0.6441\n","0.457163056851915\n","0.4358204836245535\n","0.4543723899393824\n","0.4033888533497545\n","0.3579960100216559\n","0.38514138745642174\n","  [E:  9] valid loss = 0.7207\n","... Done!\n"]},{"output_type":"execute_result","data":{"text/plain":["0.803896651822224"]},"metadata":{},"execution_count":197}]},{"cell_type":"code","source":["test_dataset = DataLoader(test_cnn, batch_size=128, shuffle=False)\n","bilstm_trainer.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SD7teIJfZHY3","executionInfo":{"status":"ok","timestamp":1649456329862,"user_tz":-120,"elapsed":516,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"2482d2ad-a5cd-4845-a46d-d236530f27f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.1071600965406275\n"]},{"output_type":"execute_result","data":{"text/plain":["1.6061549186706543"]},"metadata":{},"execution_count":198}]},{"cell_type":"markdown","source":["# New Model"],"metadata":{"id":"_RXWeWHtjp_4"}},{"cell_type":"code","source":["def dataset_creator_cnn(data, word_to_indices, label_to_indices):\n","  lista, max = create_list(data)\n","  same_length = all_same_length(lista, max)\n","  word_indices = dataset_to_indices(same_length, word_to_indices)\n","  label_ind = label_index(same_length, label_to_indices)\n","\n","  data = {}\n","  for i in range(0, len(word_indices)):\n","    data[i]={'inputs': torch.LongTensor(word_indices[i]), 'outputs': torch.LongTensor(label_ind[i])}\n","\n","  return data, max"],"metadata":{"id":"MbDTTuOuIL49"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ClassifierModel_with_cnn(nn.Module):\n","    # we provide the hyperparameters as input\n","    def __init__(self, hparams):\n","        super(ClassifierModel_with_cnn, self).__init__()\n","        print(params)\n","        self.word_embedding = nn.Embedding(hparams.vocab_size, hparams.embedding_dim)\n","\n","        self.lstm = nn.LSTM(hparams.embedding_dim, hparams.hidden_dim, \n","                            bidirectional=hparams.bidirectional,\n","                            num_layers=hparams.num_layers, \n","                            dropout = hparams.dropout)\n","        \n","        lstm_output_dim = hparams.hidden_dim * 2\n","\n","        self.dropout = nn.Dropout(hparams.dropout)\n","        self.fc1 = nn.Linear(lstm_output_dim, hparams.hidden_dim)\n","        self.conv1 = nn.Conv1d(hparams.hidden_dim, lstm_output_dim, kernel_size=2, stride=1, padding=0)\n","        self.conv2 = nn.Conv1d(lstm_output_dim, hparams.hidden_dim, kernel_size=2, stride=1, padding=1)\n","        self.classifier = nn.Linear(lstm_output_dim, hparams.num_classes)\n","\n","    \n","    def forward(self, x):\n","        embeddings = self.word_embedding(x)\n","        embeddings = self.dropout(embeddings)\n","        o, (h, c) = self.lstm(embeddings)\n","        #print('DIMENSION o: ', o.size())\n","        o = self.dropout(o)\n","        #x = nn.GLU(o)\n","        #o.unsqueeze(0)\n","        x = self.fc1(o)\n","        print('DIM x: ', x.size())\n","        x = self.conv1(x)\n","        print('DIMENSION x1: ', x.size())\n","        #x = nn.GLU(x)\n","        x = self.dropout(x)\n","        x = self.conv2(x)\n","        x = self.dropout(x)\n","        #x = torch.flatten(x, 1)\n","        #x = torch.flatten(x, 1)\n","        #output = self.fc1(x)\n","        print('DIMENSION x2: ', x.size())\n","        output = self.classifier(x)\n","        # output = F.log_softmax(output, dim=1)\n","        #print('DIMENSION output: ', output.size())\n","        return output\n","\n","        "],"metadata":{"id":"SHOFeITaj13N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Trainer():\n","    \"\"\"Utility class to train and evaluate a model.\"\"\"\n","\n","    def __init__(\n","        self,\n","        model: nn.Module,\n","        loss_function,\n","        optimizer,\n","        label_vocab: indices_to_label,\n","        log_steps:int=10_000,\n","        log_level:int=2):\n","        \"\"\"\n","        Args:\n","            model: the model we want to train.\n","            loss_function: the loss_function to minimize.\n","            optimizer: the optimizer used to minimize the loss_function.\n","        \"\"\"\n","        self.model = model\n","        self.loss_function = loss_function\n","        self.optimizer = optimizer\n","\n","        self.label_vocab = label_vocab\n","        self.log_steps = log_steps\n","        self.log_level = log_level\n","        #self.label_vocab = label_vocab\n","\n","    def train(self, train_dataset, \n","              valid_dataset, \n","              epochs:int=1):\n","        \"\"\"\n","        Args:\n","            train_dataset: a Dataset or DatasetLoader instance containing\n","                the training instances.\n","            valid_dataset: a Dataset or DatasetLoader instance used to evaluate\n","                learning progress.\n","            epochs: the number of times to iterate over train_dataset.\n","\n","        Returns:\n","            avg_train_loss: the average training loss on train_dataset over\n","                epochs.\n","        \"\"\"\n","        assert epochs > 1 and isinstance(epochs, int)\n","        if self.log_level > 0:\n","            print('Training ...')\n","        train_loss = 0.0\n","        for epoch in range(epochs):\n","            if self.log_level > 0:\n","                print(' Epoch {:03d}'.format(epoch + 1))\n","\n","            epoch_loss = 0.0\n","            self.model.train()\n","\n","            # for each batch \n","            for step, sample in enumerate(train_dataset):\n","                inputs = sample['inputs']\n","                labels = sample['outputs']\n","                self.optimizer.zero_grad()\n","\n","                predictions = self.model(inputs)\n","                predictions = predictions.view(-1, predictions.shape[-1])\n","                labels = labels.view(-1)\n","                # labels  [[1,2,3], [18, 12, 3]] after the view(-1) [1,2,3, 18, 12, 3]\n","                \n","                sample_loss = self.loss_function(predictions, labels)\n","                sample_loss.backward()\n","                self.optimizer.step()\n","               \n","                epoch_loss += sample_loss.tolist()\n","\n","                if self.log_level > 1 and step % self.log_steps == self.log_steps - 1:\n","                    print('\\t[E: {:2d} @ step {}] current avg loss = {:0.4f}'.format(epoch, step, epoch_loss / (step + 1)))\n","            \n","            avg_epoch_loss = epoch_loss / len(train_dataset)\n","            train_loss += avg_epoch_loss\n","            if self.log_level > 0:\n","                print('\\t[E: {:2d}] train loss = {:0.4f}'.format(epoch, avg_epoch_loss))\n","\n","            valid_loss = self.evaluate(valid_dataset)\n","            \n","            if self.log_level > 0:\n","                print('  [E: {:2d}] valid loss = {:0.4f}'.format(epoch, valid_loss))\n","\n","        if self.log_level > 0:\n","            print('... Done!')\n","        \n","        avg_epoch_loss = train_loss / epochs\n","        return avg_epoch_loss\n","    \n","\n","    def evaluate(self, valid_dataset):\n","        \"\"\"\n","        Args:\n","            valid_dataset: the dataset to use to evaluate the model.\n","\n","        Returns:\n","            avg_valid_loss: the average validation loss over valid_dataset.\n","        \"\"\"\n","        valid_loss = 0.0\n","        # set dropout to 0!! Needed when we are in inference mode.\n","        print('sono qui')\n","        self.model.eval()\n","        print('passato')\n","        with torch.no_grad():\n","            for sample in valid_dataset:\n","                inputs = sample['inputs']\n","                labels = sample['outputs']\n","\n","                print('middle')\n","                predictions = self.model(inputs)\n","                predictions = predictions.view(-1, predictions.shape[-1])\n","                labels = labels.view(-1)\n","                print('LABRLS: ', labels.tolist())\n","                top_label_scores, top_label_indices = torch.max(predictions, -1)\n","                top_label_indices = top_label_indices.tolist()\n","                print('PREDICTION: ', top_label_indices)\n","                sample_loss = self.loss_function(predictions, labels)\n","                valid_loss += sample_loss.tolist()\n","        print('yesss')\n","        return valid_loss / len(valid_dataset)\n","\n","    def predict(self, x):\n","        \"\"\"\n","        Args:\n","            x: a tensor of indices.\n","        Returns: \n","            A list containing the predicted POS tag for each token in the\n","            input sentences.\n","        \"\"\"\n","        self.model.eval()\n","        with torch.no_grad():\n","            logits = self.model(x)\n","            predictions = torch.argmax(logits, -1)\n","            return logits, predictions\n","    \n","    "],"metadata":{"id":"tn1OjPrIoi-P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CNNParams():\n","    vocab_size = len(word_to_indices)\n","    hidden_dim = 128\n","    embedding_dim = 100\n","    max = max\n","    num_classes = len(indices_to_label)\n","    bidirectional = True\n","    num_layers = 3\n","    dropout = 0.05\n","params = CNNParams()"],"metadata":{"id":"7qW2LEmMosE8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","import torch.optim as optim\n","#window_size, window_shift = 100, 100\n","#device = \"cuda\"\n","training_data = load_dataset('/content/drive/MyDrive/data (1)/train.tsv')\n","dev_data = load_dataset('/content/drive/MyDrive/data (1)/dev.tsv')\n","trainingset = dataset_creator_cnn(training_data, word_to_indices, label_to_indices)\n","devset = dataset_creator_cnn(dev_data, word_to_indices, label_to_indices)\n","#testset = POSTaggingDataset(test_file, window_size, window_shift, device=device)\n","\n","#trainingset.index_dataset(vocabulary, label_vocabulary)\n","#devset.index_dataset(vocabulary, label_vocabulary)\n","#testset.index_dataset(vocabulary, label_vocabulary)\n","\n","train_dataset = DataLoader(trainingset, batch_size=128, shuffle=True)\n","valid_dataset = DataLoader(devset, batch_size=128, shuffle=False)\n","#test_dataset = DataLoader(testset, batch_size=128, shuffle=False)"],"metadata":{"id":"kAVxkMnVHOW6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_cnn_classifier = ClassifierModel_with_cnn(params)#.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1kN1gzAcom8e","executionInfo":{"status":"ok","timestamp":1649287441702,"user_tz":-120,"elapsed":1148,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"e3826055-090e-4fe2-b924-00e6d4993d62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.CNNParams object at 0x7f8de611f810>\n"]}]},{"cell_type":"code","source":["lstm_cnn_trainer = Trainer(\n","    model = lstm_cnn_classifier,\n","    loss_function = nn.CrossEntropyLoss(ignore_index=label_to_indices['PAD']),\n","    optimizer = optim.Adam(lstm_cnn_classifier.parameters()),\n","    label_vocab=indices_to_label\n",")"],"metadata":{"id":"UfZ5Te20o8cV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_cnn_trainer.train(train_dataset, valid_dataset, 8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"AFw_2s9WpGjS","executionInfo":{"status":"error","timestamp":1649287444106,"user_tz":-120,"elapsed":12,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"6b253e56-7da9-45f0-a995-b5059231df6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training ...\n"," Epoch 001\n","DIM x:  torch.Size([128, 41, 128])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-499-2cf52ee1429e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm_cnn_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-473-99397b8d5720>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, valid_dataset, epochs)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-496-a25898b665a4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DIM x: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DIMENSION x1: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#x = nn.GLU(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    296\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    297\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 298\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [256, 128, 2], expected input[128, 41, 128] to have 128 channels, but got 41 channels instead"]}]},{"cell_type":"markdown","source":["# Valutation"],"metadata":{"id":"7Skoyi0fgnMb"}},{"cell_type":"code","source":["from sklearn.metrics import precision_score as sk_precision\n","def compute_precision(model:nn.Module, l_dataset:DataLoader, l_label_vocab:label_to_indices):\n","    all_predictions = list()\n","    all_labels = list()\n","    for indexed_elem in l_dataset:\n","        indexed_in = indexed_elem[\"inputs\"]\n","        indexed_labels = indexed_elem[\"outputs\"]\n","        predictions = model(indexed_in)\n","        predictions = torch.argmax(predictions, -1).view(-1)\n","        labels = indexed_labels.view(-1)\n","        valid_indices = labels != 0\n","        \n","        valid_predictions = predictions[valid_indices]\n","        valid_labels = labels[valid_indices]\n","        \n","        all_predictions.extend(valid_predictions.tolist())\n","        all_labels.extend(valid_labels.tolist())\n","    # global precision. Does take class imbalance into account.\n","    micro_precision = sk_precision(all_labels, all_predictions, average=\"micro\", zero_division=0)\n","    # precision per class and arithmetic average of them. Does not take into account class imbalance.\n","    macro_precision = sk_precision(all_labels, all_predictions, average=\"macro\", zero_division=0)\n","    per_class_precision = sk_precision(all_labels, all_predictions, labels = list(range(len(l_label_vocab))), average=None, zero_division=0)\n","    \n","    return {\"micro_precision\":micro_precision,\n","            \"macro_precision\":macro_precision, \n","            \"per_class_precision\":per_class_precision}\n"],"metadata":{"id":"hscMZo6igmZG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["precisions = compute_precision(bilstm_classifier, test_dataset, label_to_indices)\n","per_class_precision = precisions[\"per_class_precision\"]\n","print(\"Micro Precision: {}\\nMacro Precision: {}\".format(precisions[\"micro_precision\"], precisions[\"macro_precision\"]))\n","print(\"Per class Precision:\")\n","'''\n","for idx_class, precision in sorted(enumerate(per_class_precision), key=lambda elem: -elem[1]):\n","    label = label_to_indices.itos[idx_class]\n","    print(label, precision)\n","    '''"],"metadata":{"id":"nq_bg4SMgubw","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1649454681730,"user_tz":-120,"elapsed":449,"user":{"displayName":"matteo zaramella","userId":"10742928843186045982"}},"outputId":"231cb621-ba0e-4bae-f198-a7566d59c4fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Micro Precision: 0.6615384615384615\n","Macro Precision: 0.11848072562358276\n","Per class Precision:\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\nfor idx_class, precision in sorted(enumerate(per_class_precision), key=lambda elem: -elem[1]):\\n    label = label_to_indices.itos[idx_class]\\n    print(label, precision)\\n    '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":190}]}]}